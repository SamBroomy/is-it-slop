{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41f0ed75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1.0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "from loguru import logger\n",
    "from skl2onnx import convert_sklearn, to_onnx\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from slop_pre_processing import TfidfVectorizer, VectorizerParams, __version__\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)  # Or INFO, WARNING, etc.\n",
    "\n",
    "print(__version__)\n",
    "\n",
    "# vectorizer = TfidfVectorizer(ngram_range=(3, 5), min_df=1)\n",
    "# print(vectorizer)\n",
    "# sparse = vectorizer.fit_transform(\n",
    "#     [\"this is a sample\", \"this is another example sample\"],\n",
    "# )\n",
    "# print(vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8091c618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (44_868, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>text</th><th>label</th><th>prompt_name</th><th>source</th><th>RDizzl3_seven</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>str</td><td>bool</td></tr></thead><tbody><tr><td>&quot;Phones\n",
       "\n",
       "Modern humans today ar…</td><td>0</td><td>&quot;Phones and driving&quot;</td><td>&quot;persuade_corpus&quot;</td><td>false</td></tr><tr><td>&quot;This essay will explain if dri…</td><td>0</td><td>&quot;Phones and driving&quot;</td><td>&quot;persuade_corpus&quot;</td><td>false</td></tr><tr><td>&quot;Driving while the use of cellu…</td><td>0</td><td>&quot;Phones and driving&quot;</td><td>&quot;persuade_corpus&quot;</td><td>false</td></tr><tr><td>&quot;Phones &amp; Driving\n",
       "\n",
       "Drivers shou…</td><td>0</td><td>&quot;Phones and driving&quot;</td><td>&quot;persuade_corpus&quot;</td><td>false</td></tr><tr><td>&quot;Cell Phone Operation While Dri…</td><td>0</td><td>&quot;Phones and driving&quot;</td><td>&quot;persuade_corpus&quot;</td><td>false</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;Dear Senator,\n",
       "\n",
       "I am writing to…</td><td>1</td><td>&quot;Does the electoral college wor…</td><td>&quot;kingki19_palm&quot;</td><td>true</td></tr><tr><td>&quot;Dear Senator,\n",
       "\n",
       "I am writing to…</td><td>1</td><td>&quot;Does the electoral college wor…</td><td>&quot;kingki19_palm&quot;</td><td>true</td></tr><tr><td>&quot;Dear Senator,\n",
       "\n",
       "I am writing to…</td><td>1</td><td>&quot;Does the electoral college wor…</td><td>&quot;kingki19_palm&quot;</td><td>true</td></tr><tr><td>&quot;Dear Senator,\n",
       "\n",
       "I am writing to…</td><td>1</td><td>&quot;Does the electoral college wor…</td><td>&quot;kingki19_palm&quot;</td><td>true</td></tr><tr><td>&quot;Dear Senator,\n",
       "\n",
       "I am writing to…</td><td>1</td><td>&quot;Does the electoral college wor…</td><td>&quot;kingki19_palm&quot;</td><td>true</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (44_868, 5)\n",
       "┌───────────────────────────────────┬───────┬────────────────────┬─────────────────┬───────────────┐\n",
       "│ text                              ┆ label ┆ prompt_name        ┆ source          ┆ RDizzl3_seven │\n",
       "│ ---                               ┆ ---   ┆ ---                ┆ ---             ┆ ---           │\n",
       "│ str                               ┆ i64   ┆ str                ┆ str             ┆ bool          │\n",
       "╞═══════════════════════════════════╪═══════╪════════════════════╪═════════════════╪═══════════════╡\n",
       "│ Phones                            ┆ 0     ┆ Phones and driving ┆ persuade_corpus ┆ false         │\n",
       "│                                   ┆       ┆                    ┆                 ┆               │\n",
       "│ Modern humans today ar…           ┆       ┆                    ┆                 ┆               │\n",
       "│ This essay will explain if dri…   ┆ 0     ┆ Phones and driving ┆ persuade_corpus ┆ false         │\n",
       "│ Driving while the use of cellu…   ┆ 0     ┆ Phones and driving ┆ persuade_corpus ┆ false         │\n",
       "│ Phones & Driving                  ┆ 0     ┆ Phones and driving ┆ persuade_corpus ┆ false         │\n",
       "│                                   ┆       ┆                    ┆                 ┆               │\n",
       "│ Drivers shou…                     ┆       ┆                    ┆                 ┆               │\n",
       "│ Cell Phone Operation While Dri…   ┆ 0     ┆ Phones and driving ┆ persuade_corpus ┆ false         │\n",
       "│ …                                 ┆ …     ┆ …                  ┆ …               ┆ …             │\n",
       "│ Dear Senator,                     ┆ 1     ┆ Does the electoral ┆ kingki19_palm   ┆ true          │\n",
       "│                                   ┆       ┆ college wor…       ┆                 ┆               │\n",
       "│ I am writing to…                  ┆       ┆                    ┆                 ┆               │\n",
       "│ Dear Senator,                     ┆ 1     ┆ Does the electoral ┆ kingki19_palm   ┆ true          │\n",
       "│                                   ┆       ┆ college wor…       ┆                 ┆               │\n",
       "│ I am writing to…                  ┆       ┆                    ┆                 ┆               │\n",
       "│ Dear Senator,                     ┆ 1     ┆ Does the electoral ┆ kingki19_palm   ┆ true          │\n",
       "│                                   ┆       ┆ college wor…       ┆                 ┆               │\n",
       "│ I am writing to…                  ┆       ┆                    ┆                 ┆               │\n",
       "│ Dear Senator,                     ┆ 1     ┆ Does the electoral ┆ kingki19_palm   ┆ true          │\n",
       "│                                   ┆       ┆ college wor…       ┆                 ┆               │\n",
       "│ I am writing to…                  ┆       ┆                    ┆                 ┆               │\n",
       "│ Dear Senator,                     ┆ 1     ┆ Does the electoral ┆ kingki19_palm   ┆ true          │\n",
       "│                                   ┆       ┆ college wor…       ┆                 ┆               │\n",
       "│ I am writing to…                  ┆       ┆                    ┆                 ┆               │\n",
       "└───────────────────────────────────┴───────┴────────────────────┴─────────────────┴───────────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.scan_csv(\"../data/raw/train_v2_drcat_02.csv\").unique([\"text\"], maintain_order=True).collect()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d5e2b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-24 21:53:36.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m1\u001b[0m - \u001b[1mLoaded 44868 samples\u001b[0m\n",
      "\u001b[32m2025-11-24 21:53:36.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m10\u001b[0m - \u001b[1mTraining samples: 35894, Validation samples: 8974\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Loaded {len(df)} samples\")\n",
    "# Split data\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df[\"text\"].to_numpy(),\n",
    "    df[\"label\"].to_numpy(),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"label\"]\n",
    ")\n",
    "logger.info(f\"Training samples: {len(X_train)}, Validation samples: {len(X_val)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37bf8a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Advice about receiving advice\\n\\nDoing something one way and then realizing there was a great amount of other options is a very annoying (and unfortunately, very common) case. It's even more annoying when you don't realize what the other solution was because then you can never grow as a person. People should ask more than one person for advice when seeking it because not everything will work for everyone and it's always better to hear from different sources.\\n\\nNot everything will work for everyone, as everybody has their own way of dealing with certain things. Say there's a student in algebra honors and they are studying for a test that is stressing them out very much. Now, this student has trouble paying attention in class, and as a result of that, they often don't have the best of notes. If the student's parent is giving them advice and the parent says to the student that they should check their notes, the student will most likely have to seek help elsewhere because that advice is not very good for them in particular.\\n\\nIt's always better to hear from different sources. There are lots of times when you need to seek multiple solutions. In science labs, multiple trials are required to find out if the initial hypothesis was correct. When writing about current events, one must gather information from different sources or they could be risking the possibility of being biased. It's no different when people are seeking advice from someone. If somebody receives advice from one person and they aren't happy with outcome of the advice they took, chances are they didn't hear from enough people and a different solution was just waiting for them to try it out.\\n\\nAt the end of the day, receiving advice from multiple people is the best thing to do because not everything will work for everyone and it is always better to hear from more than one source.   \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5edb400f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-24 21:53:36.955\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mFitting Rust TF-IDF vectorizer...\u001b[0m\n",
      "DEBUG:slop_pre_processing.pre_processor.vectorizer.tfidf_vectorizer:Fitting TfidfVectorizer num_texts=35894\n",
      "DEBUG:slop_pre_processing.pre_processor.vectorizer.count_vectorizer:Optimized fit_transform: tokenizing and computing n-grams once num_texts=35894\n",
      "DEBUG:slop_pre_processing.pre_processor.vectorizer.tokenizer:Using parallel tokenization num_texts=35894\n",
      "DEBUG:slop_pre_processing.pre_processor.vectorizer.count_vectorizer:Computing n-grams for all documents\n",
      "DEBUG:slop_pre_processing.pre_processor.vectorizer.count_vectorizer:Fitting vectorizer from cached n-grams\n",
      "DEBUG:slop_pre_processing.pre_processor.vectorizer.count_vectorizer:Building vocabulary from tokenized texts\n",
      "DEBUG:slop_pre_processing.pre_processor.vectorizer.count_vectorizer:Using pre-computed n-grams for vocabulary building\n",
      "DEBUG:slop_pre_processing.pre_processor.vectorizer.count_vectorizer:Applying min_df filtering min_df=10\n",
      "DEBUG:slop_pre_processing.pre_processor.vectorizer.count_vectorizer:Vocabulary filtered by min_df original_size=24101527 filtered_size=380032\n",
      "DEBUG:slop_pre_processing.pre_processor.vectorizer.count_vectorizer:CountVectorizer fitting complete vocab_size=380032\n",
      "DEBUG:slop_pre_processing.pre_processor.vectorizer.count_vectorizer:Transforming using cached n-grams\n",
      "DEBUG:slop_pre_processing.pre_processor.vectorizer.count_vectorizer:Text transformation complete non_zero_entries=13346537\n",
      "DEBUG:slop_pre_processing.pre_processor.vectorizer.count_vectorizer:fit_transform complete with single n-gram computation\n",
      "DEBUG:slop_pre_processing.pre_processor.vectorizer.tfidf_vectorizer:Calculating IDF values\n",
      "DEBUG:slop_pre_processing.pre_processor.vectorizer.tfidf_vectorizer:IDF calculation complete\n",
      "DEBUG:slop_pre_processing.pre_processor.vectorizer.tfidf_vectorizer:Transforming texts using TfidfVectorizer num_texts=35894\n",
      "DEBUG:slop_pre_processing.pre_processor.vectorizer.count_vectorizer:Transforming texts using CountVectorizer num_texts=35894\n",
      "DEBUG:slop_pre_processing.pre_processor.vectorizer.tokenizer:Using parallel tokenization num_texts=35894\n",
      "DEBUG:slop_pre_processing.pre_processor.vectorizer.count_vectorizer:Text transformation complete non_zero_entries=13346537\n",
      "DEBUG:slop_pre_processing.pre_processor.vectorizer.tfidf_vectorizer:Transforming texts using TfidfVectorizer num_texts=8974\n",
      "DEBUG:slop_pre_processing.pre_processor.vectorizer.count_vectorizer:Transforming texts using CountVectorizer num_texts=8974\n",
      "DEBUG:slop_pre_processing.pre_processor.vectorizer.tokenizer:Using parallel tokenization num_texts=8974\n",
      "DEBUG:slop_pre_processing.pre_processor.vectorizer.count_vectorizer:Text transformation complete non_zero_entries=3259032\n"
     ]
    }
   ],
   "source": [
    "# Use Rust preprocessing (via Python bindings)\n",
    "logger.info(\"Fitting Rust TF-IDF vectorizer...\")\n",
    "vectorizer = TfidfVectorizer((3, 5), min_df=10)\n",
    "from scipy.sparse import csr_array\n",
    "# fit_transform returns scipy.sparse.csr_matrix\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = vectorizer.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06f5f552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35894, 380032)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tfidf.shape)  # Should be (num_samples, 380032)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab329ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train_tfidf))\n",
    "print(type(X_val_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c546c225",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = csr_array(X_train_tfidf)\n",
    "X_val_tfidf = csr_array(X_val_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7e1c66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-24 21:54:01.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m1\u001b[0m - \u001b[1mFeature matrix: (35894, 380032)\u001b[0m\n",
      "\u001b[32m2025-11-24 21:54:01.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mSparsity: 99.90%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Feature matrix: {X_train_tfidf.shape}\")\n",
    "logger.info(f\"Sparsity: {100 * (1 - X_train_tfidf.nnz / np.prod(X_train_tfidf.shape)):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecfe3d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-24 21:54:01.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m2\u001b[0m - \u001b[1mTraining ensemble...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Train ensemble\n",
    "logger.info(\"Training ensemble...\")\n",
    "# Recreate ensemble with flatten_transform=False\n",
    "nb = MultinomialNB(alpha=0.02)\n",
    "sgd = SGDClassifier(max_iter=8000, tol=1e-4, loss=\"modified_huber\", random_state=42)\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[(\"nb\", nb), (\"sgd\", sgd)],\n",
    "    weights=[0.4, 0.6],\n",
    "    voting=\"soft\",\n",
    "    n_jobs=-1,\n",
    "    flatten_transform=False\n",
    ")\n",
    "# Retrain\n",
    "ensemble.fit(X_train_tfidf, y_train)\n",
    "ensemble.weights = np.array(ensemble.weights)  # Convert to numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51b1a269",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-11-24 21:54:02.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mValidation AUC: 0.9997\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "val_preds = ensemble.predict_proba(X_val_tfidf)[:, 1]\n",
    "val_auc = roc_auc_score(y_val, val_preds)\n",
    "logger.info(f\"Validation AUC: {val_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c840baf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 1], shape=(8974,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51d8e2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics (threshold=0.50):\n",
      "  Accuracy:  0.9936\n",
      "  Precision: 0.9980\n",
      "  Recall:    0.9857\n",
      "  F1 Score:  0.9918\n",
      "  TP: 3450, FP: 7, TN: 5467, FN: 50\n",
      "\n",
      "Confusion Matrix:\n",
      "              Predicted\n",
      "              0      1\n",
      "Actual  0     5467      7\n",
      "        1       50   3450\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "threshold = 0.5\n",
    "y_pred_labels = (val_preds >= threshold).astype(float)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_val, y_pred_labels).ravel()\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(y_val, y_pred_labels)\n",
    "precision = precision_score(y_val, y_pred_labels, zero_division=0)\n",
    "recall = recall_score(y_val, y_pred_labels, zero_division=0)\n",
    "f1 = f1_score(y_val, y_pred_labels, zero_division=0)\n",
    "print(f\"\\nMetrics (threshold={threshold:.2f}):\")\n",
    "print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall:    {recall:.4f}\")\n",
    "print(f\"  F1 Score:  {f1:.4f}\")\n",
    "print(f\"  TP: {tp}, FP: {fp}, TN: {tn}, FN: {fn}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(\"              Predicted\")\n",
    "print(\"              0      1\")\n",
    "print(f\"Actual  0    {tn:5d}  {fp:5d}\")\n",
    "print(f\"        1    {fn:5d}  {tp:5d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b38d2141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse array of dtype 'float64'\n",
       "\twith 13346537 stored elements and shape (35894, 380032)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25b95a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:skl2onnx:[Var] +Variable('X', 'X', type=FloatTensorType(shape=[None, 380032]))\n",
      "DEBUG:skl2onnx:[Var] update is_root=True for Variable('X', 'X', type=FloatTensorType(shape=[None, 380032]))\n",
      "DEBUG:skl2onnx:[parsing] found alias='SklearnVotingClassifier' for type=<class 'sklearn.ensemble._voting.VotingClassifier'>.\n",
      "DEBUG:skl2onnx:[Op] +Operator(type='SklearnVotingClassifier', onnx_name='SklearnVotingClassifier', inputs='', outputs='', raw_operator=VotingClassifier(estimators=[('nb',MultinomialNB(alpha=0.02)),('sgd',SGDClassifier(loss='modified_huber',max_iter=8000,random_state=42,tol=0.0001))],flatten_transform=False,n_jobs=-1,voting='soft',weights=array([0.4,0.6])))\n",
      "DEBUG:skl2onnx:[Op] add In Variable('X', 'X', type=FloatTensorType(shape=[None, 380032])) to Operator(type='SklearnVotingClassifier', onnx_name='SklearnVotingClassifier', inputs='X', outputs='', raw_operator=VotingClassifier(estimators=[('nb',MultinomialNB(alpha=0.02)),('sgd',SGDClassifier(loss='modified_huber',max_iter=8000,random_state=42,tol=0.0001))],flatten_transform=False,n_jobs=-1,voting='soft',weights=array([0.4,0.6])))\n",
      "DEBUG:skl2onnx:[Var] +Variable('label', 'label', type=Int64TensorType(shape=[]))\n",
      "DEBUG:skl2onnx:[Var] +Variable('probabilities', 'probabilities', type=FloatTensorType(shape=[]))\n",
      "DEBUG:skl2onnx:[Var] set parent for Variable('label', 'label', type=Int64TensorType(shape=[])), parent=Operator(type='SklearnVotingClassifier', onnx_name='SklearnVotingClassifier', inputs='X', outputs='', raw_operator=VotingClassifier(estimators=[('nb',MultinomialNB(alpha=0.02)),('sgd',SGDClassifier(loss='modified_huber',max_iter=8000,random_state=42,tol=0.0001))],flatten_transform=False,n_jobs=-1,voting='soft',weights=array([0.4,0.6])))\n",
      "DEBUG:skl2onnx:[Op] add Out Variable('label', 'label', type=Int64TensorType(shape=[])) to Operator(type='SklearnVotingClassifier', onnx_name='SklearnVotingClassifier', inputs='X', outputs='label', raw_operator=VotingClassifier(estimators=[('nb',MultinomialNB(alpha=0.02)),('sgd',SGDClassifier(loss='modified_huber',max_iter=8000,random_state=42,tol=0.0001))],flatten_transform=False,n_jobs=-1,voting='soft',weights=array([0.4,0.6])))\n",
      "DEBUG:skl2onnx:[Var] set parent for Variable('probabilities', 'probabilities', type=FloatTensorType(shape=[])), parent=Operator(type='SklearnVotingClassifier', onnx_name='SklearnVotingClassifier', inputs='X', outputs='label', raw_operator=VotingClassifier(estimators=[('nb',MultinomialNB(alpha=0.02)),('sgd',SGDClassifier(loss='modified_huber',max_iter=8000,random_state=42,tol=0.0001))],flatten_transform=False,n_jobs=-1,voting='soft',weights=array([0.4,0.6])))\n",
      "DEBUG:skl2onnx:[Op] add Out Variable('probabilities', 'probabilities', type=FloatTensorType(shape=[])) to Operator(type='SklearnVotingClassifier', onnx_name='SklearnVotingClassifier', inputs='X', outputs='label,probabilities', raw_operator=VotingClassifier(estimators=[('nb',MultinomialNB(alpha=0.02)),('sgd',SGDClassifier(loss='modified_huber',max_iter=8000,random_state=42,tol=0.0001))],flatten_transform=False,n_jobs=-1,voting='soft',weights=array([0.4,0.6])))\n",
      "DEBUG:skl2onnx:[Var] update is_leaf=True for Variable('label', 'label', type=Int64TensorType(shape=[]))\n",
      "DEBUG:skl2onnx:[Var] update is_leaf=True for Variable('probabilities', 'probabilities', type=FloatTensorType(shape=[]))\n",
      "DEBUG:skl2onnx:[Var] update is_fed=True for Variable('X', 'X', type=FloatTensorType(shape=[None, 380032])), parent=None\n",
      "DEBUG:skl2onnx:[Var] update is_fed=False for Variable('label', 'label', type=Int64TensorType(shape=[])), parent=Operator(type='SklearnVotingClassifier', onnx_name='SklearnVotingClassifier', inputs='X', outputs='label,probabilities', raw_operator=VotingClassifier(estimators=[('nb',MultinomialNB(alpha=0.02)),('sgd',SGDClassifier(loss='modified_huber',max_iter=8000,random_state=42,tol=0.0001))],flatten_transform=False,n_jobs=-1,voting='soft',weights=array([0.4,0.6])))\n",
      "DEBUG:skl2onnx:[Var] update is_fed=False for Variable('probabilities', 'probabilities', type=FloatTensorType(shape=[])), parent=Operator(type='SklearnVotingClassifier', onnx_name='SklearnVotingClassifier', inputs='X', outputs='label,probabilities', raw_operator=VotingClassifier(estimators=[('nb',MultinomialNB(alpha=0.02)),('sgd',SGDClassifier(loss='modified_huber',max_iter=8000,random_state=42,tol=0.0001))],flatten_transform=False,n_jobs=-1,voting='soft',weights=array([0.4,0.6])))\n",
      "DEBUG:skl2onnx:[Op] update is_evaluated=False for Operator(type='SklearnVotingClassifier', onnx_name='SklearnVotingClassifier', inputs='X', outputs='label,probabilities', raw_operator=VotingClassifier(estimators=[('nb',MultinomialNB(alpha=0.02)),('sgd',SGDClassifier(loss='modified_huber',max_iter=8000,random_state=42,tol=0.0001))],flatten_transform=False,n_jobs=-1,voting='soft',weights=array([0.4,0.6])))\n",
      "DEBUG:skl2onnx:[Shape2] call infer_types for Operator(type='SklearnVotingClassifier', onnx_name='SklearnVotingClassifier', inputs='X', outputs='label,probabilities', raw_operator=VotingClassifier(estimators=[('nb',MultinomialNB(alpha=0.02)),('sgd',SGDClassifier(loss='modified_huber',max_iter=8000,random_state=42,tol=0.0001))],flatten_transform=False,n_jobs=-1,voting='soft',weights=array([0.4,0.6])))\n",
      "DEBUG:skl2onnx:[Shape-a] Operator(type='SklearnVotingClassifier', onnx_name='SklearnVotingClassifier', inputs='X', outputs='label,probabilities', raw_operator=VotingClassifier(estimators=[('nb',MultinomialNB(alpha=0.02)),('sgd',SGDClassifier(loss='modified_huber',max_iter=8000,random_state=42,tol=0.0001))],flatten_transform=False,n_jobs=-1,voting='soft',weights=array([0.4,0.6]))) fed 'True' - 'FalseFalse'\n",
      "DEBUG:skl2onnx:[Var] update type for Variable('label', 'label', type=Int64TensorType(shape=[]))\n",
      "DEBUG:skl2onnx:[Shape-b] Operator(type='SklearnVotingClassifier', onnx_name='SklearnVotingClassifier', inputs='X', outputs='label,probabilities', raw_operator=VotingClassifier(estimators=[('nb',MultinomialNB(alpha=0.02)),('sgd',SGDClassifier(loss='modified_huber',max_iter=8000,random_state=42,tol=0.0001))],flatten_transform=False,n_jobs=-1,voting='soft',weights=array([0.4,0.6]))) inputs=[Variable('X', 'X', type=FloatTensorType(shape=[None, 380032]))] - outputs=[Variable('label', 'label', type=Int64TensorType(shape=[None])), Variable('probabilities', 'probabilities', type=FloatTensorType(shape=[None, 2]))]\n",
      "DEBUG:skl2onnx:[Conv] call Operator(type='SklearnVotingClassifier', onnx_name='SklearnVotingClassifier', inputs='X', outputs='label,probabilities', raw_operator=VotingClassifier(estimators=[('nb',MultinomialNB(alpha=0.02)),('sgd',SGDClassifier(loss='modified_huber',max_iter=8000,random_state=42,tol=0.0001))],flatten_transform=False,n_jobs=-1,voting='soft',weights=array([0.4,0.6]))) fed 'True' - 'FalseFalse'\n",
      "DEBUG:skl2onnx:[Init] 'classes_ind', 7, (1, 2)\n",
      "DEBUG:skl2onnx:[Op] +Operator(type='SklearnMultinomialNB', onnx_name='SklearnMultinomialNB', inputs='', outputs='', raw_operator=MultinomialNB(alpha=0.02))\n",
      "DEBUG:skl2onnx:[Var] +Variable('label_0', 'label_0', type=Int64TensorType(shape=[]))\n",
      "DEBUG:skl2onnx:[Var] +Variable('voting_proba_0', 'voting_proba_0', type=FloatTensorType(shape=[]))\n",
      "DEBUG:skl2onnx:[Var] set parent for Variable('label_0', 'label_0', type=Int64TensorType(shape=[])), parent=Operator(type='SklearnMultinomialNB', onnx_name='SklearnMultinomialNB', inputs='X', outputs='', raw_operator=MultinomialNB(alpha=0.02))\n",
      "DEBUG:skl2onnx:[Op] add Out Variable('label_0', 'label_0', type=Int64TensorType(shape=[])) to Operator(type='SklearnMultinomialNB', onnx_name='SklearnMultinomialNB', inputs='X', outputs='label_0', raw_operator=MultinomialNB(alpha=0.02))\n",
      "DEBUG:skl2onnx:[Var] set parent for Variable('voting_proba_0', 'voting_proba_0', type=FloatTensorType(shape=[])), parent=Operator(type='SklearnMultinomialNB', onnx_name='SklearnMultinomialNB', inputs='X', outputs='label_0', raw_operator=MultinomialNB(alpha=0.02))\n",
      "DEBUG:skl2onnx:[Op] add Out Variable('voting_proba_0', 'voting_proba_0', type=FloatTensorType(shape=[])) to Operator(type='SklearnMultinomialNB', onnx_name='SklearnMultinomialNB', inputs='X', outputs='label_0,voting_proba_0', raw_operator=MultinomialNB(alpha=0.02))\n",
      "DEBUG:skl2onnx:[Init] 'w0', 1, [1]\n",
      "DEBUG:skl2onnx:[Node] 'Mul' - 'voting_proba_0,w0' -> 'wprob_name' (name='Mul')\n",
      "DEBUG:skl2onnx:[Op] +Operator(type='SklearnSGDClassifier', onnx_name='SklearnSGDClassifier', inputs='', outputs='', raw_operator=SGDClassifier(loss='modified_huber', max_iter=8000, random_state=42, tol=0.0001))\n",
      "DEBUG:skl2onnx:[Var] +Variable('label_1', 'label_1', type=Int64TensorType(shape=[]))\n",
      "DEBUG:skl2onnx:[Var] +Variable('voting_proba_1', 'voting_proba_1', type=FloatTensorType(shape=[]))\n",
      "DEBUG:skl2onnx:[Var] set parent for Variable('label_1', 'label_1', type=Int64TensorType(shape=[])), parent=Operator(type='SklearnSGDClassifier', onnx_name='SklearnSGDClassifier', inputs='X', outputs='', raw_operator=SGDClassifier(loss='modified_huber', max_iter=8000, random_state=42, tol=0.0001))\n",
      "DEBUG:skl2onnx:[Op] add Out Variable('label_1', 'label_1', type=Int64TensorType(shape=[])) to Operator(type='SklearnSGDClassifier', onnx_name='SklearnSGDClassifier', inputs='X', outputs='label_1', raw_operator=SGDClassifier(loss='modified_huber', max_iter=8000, random_state=42, tol=0.0001))\n",
      "DEBUG:skl2onnx:[Var] set parent for Variable('voting_proba_1', 'voting_proba_1', type=FloatTensorType(shape=[])), parent=Operator(type='SklearnSGDClassifier', onnx_name='SklearnSGDClassifier', inputs='X', outputs='label_1', raw_operator=SGDClassifier(loss='modified_huber', max_iter=8000, random_state=42, tol=0.0001))\n",
      "DEBUG:skl2onnx:[Op] add Out Variable('voting_proba_1', 'voting_proba_1', type=FloatTensorType(shape=[])) to Operator(type='SklearnSGDClassifier', onnx_name='SklearnSGDClassifier', inputs='X', outputs='label_1,voting_proba_1', raw_operator=SGDClassifier(loss='modified_huber', max_iter=8000, random_state=42, tol=0.0001))\n",
      "DEBUG:skl2onnx:[Init] 'w1', 1, [1]\n",
      "DEBUG:skl2onnx:[Node] 'Mul' - 'voting_proba_1,w1' -> 'wprob_name1' (name='Mul1')\n",
      "DEBUG:skl2onnx:[Node] 'Sum' - 'wprob_name,wprob_name1' -> 'probabilities' (name='Sum')\n",
      "DEBUG:skl2onnx:[Node] 'ArgMax' - 'probabilities' -> 'label_name' (name='ArgMax')\n",
      "DEBUG:skl2onnx:[Init] 'classes', 6, (2,)\n",
      "DEBUG:skl2onnx:[Node] 'ArrayFeatureExtractor' - 'classes,label_name' -> 'array_feature_extractor_result' (name='ArrayFeatureExtractor')\n",
      "DEBUG:skl2onnx:[Node] 'Cast' - 'array_feature_extractor_result' -> 'cast2_result' (name='Cast')\n",
      "DEBUG:skl2onnx:[Init] 'shape_tensor', 7, [1]\n",
      "DEBUG:skl2onnx:[Node] 'Reshape' - 'cast2_result,shape_tensor' -> 'reshaped_result' (name='Reshape')\n",
      "DEBUG:skl2onnx:[Node] 'Cast' - 'reshaped_result' -> 'label' (name='Cast1')\n",
      "DEBUG:skl2onnx:[Conv] end - Operator(type='SklearnVotingClassifier', onnx_name='SklearnVotingClassifier', inputs='X', outputs='label,probabilities', raw_operator=VotingClassifier(estimators=[('nb',MultinomialNB(alpha=0.02)),('sgd',SGDClassifier(loss='modified_huber',max_iter=8000,random_state=42,tol=0.0001))],flatten_transform=False,n_jobs=-1,voting='soft',weights=array([0.4,0.6])))\n",
      "DEBUG:skl2onnx:[Op] update is_evaluated=True for Operator(type='SklearnVotingClassifier', onnx_name='SklearnVotingClassifier', inputs='X', outputs='label,probabilities', raw_operator=VotingClassifier(estimators=[('nb',MultinomialNB(alpha=0.02)),('sgd',SGDClassifier(loss='modified_huber',max_iter=8000,random_state=42,tol=0.0001))],flatten_transform=False,n_jobs=-1,voting='soft',weights=array([0.4,0.6])))\n",
      "DEBUG:skl2onnx:[Var] update is_fed=True for Variable('label', 'label', type=Int64TensorType(shape=[None])), parent=Operator(type='SklearnVotingClassifier', onnx_name='SklearnVotingClassifier', inputs='X', outputs='label,probabilities', raw_operator=VotingClassifier(estimators=[('nb',MultinomialNB(alpha=0.02)),('sgd',SGDClassifier(loss='modified_huber',max_iter=8000,random_state=42,tol=0.0001))],flatten_transform=False,n_jobs=-1,voting='soft',weights=array([0.4,0.6])))\n",
      "DEBUG:skl2onnx:[Var] update is_fed=True for Variable('probabilities', 'probabilities', type=FloatTensorType(shape=[None, 2])), parent=Operator(type='SklearnVotingClassifier', onnx_name='SklearnVotingClassifier', inputs='X', outputs='label,probabilities', raw_operator=VotingClassifier(estimators=[('nb',MultinomialNB(alpha=0.02)),('sgd',SGDClassifier(loss='modified_huber',max_iter=8000,random_state=42,tol=0.0001))],flatten_transform=False,n_jobs=-1,voting='soft',weights=array([0.4,0.6])))\n",
      "DEBUG:skl2onnx:[Shape2] call infer_types for Operator(type='SklearnMultinomialNB', onnx_name='SklearnMultinomialNB', inputs='X', outputs='label_0,voting_proba_0', raw_operator=MultinomialNB(alpha=0.02))\n",
      "DEBUG:skl2onnx:[Shape-a] Operator(type='SklearnMultinomialNB', onnx_name='SklearnMultinomialNB', inputs='X', outputs='label_0,voting_proba_0', raw_operator=MultinomialNB(alpha=0.02)) fed 'True' - 'NoneNone'\n",
      "DEBUG:skl2onnx:[Var] update type for Variable('label_0', 'label_0', type=Int64TensorType(shape=[]))\n",
      "DEBUG:skl2onnx:[Shape-b] Operator(type='SklearnMultinomialNB', onnx_name='SklearnMultinomialNB', inputs='X', outputs='label_0,voting_proba_0', raw_operator=MultinomialNB(alpha=0.02)) inputs=[Variable('X', 'X', type=FloatTensorType(shape=[None, 380032]))] - outputs=[Variable('label_0', 'label_0', type=Int64TensorType(shape=[None])), Variable('voting_proba_0', 'voting_proba_0', type=FloatTensorType(shape=[None, 2]))]\n",
      "DEBUG:skl2onnx:[Conv] call Operator(type='SklearnMultinomialNB', onnx_name='SklearnMultinomialNB', inputs='X', outputs='label_0,voting_proba_0', raw_operator=MultinomialNB(alpha=0.02)) fed 'True' - 'NoneNone'\n",
      "DEBUG:skl2onnx:[Init] 'classes1', 6, (2,)\n",
      "DEBUG:skl2onnx:[Node] 'Identity' - 'classes' -> 'classes1' (name='classes1_op')\n",
      "DEBUG:skl2onnx:[Init] 'feature_log_prob', 1, (380032, 2)\n",
      "DEBUG:skl2onnx:[Init] 'class_log_prior', 1, (1, 2)\n",
      "DEBUG:skl2onnx:[Node] 'MatMul' - 'X,feature_log_prob' -> 'matmul_result' (name='MatMul')\n",
      "DEBUG:skl2onnx:[Node] 'Add' - 'matmul_result,class_log_prior' -> 'sum_result' (name='Add')\n",
      "DEBUG:skl2onnx:[Node] 'ArgMax' - 'sum_result' -> 'argmax_output' (name='ArgMax1')\n",
      "DEBUG:skl2onnx:[Node] 'ReduceLogSumExp' - 'sum_result' -> 'reduce_log_sum_exp_result' (name='ReduceLogSumExp')\n",
      "DEBUG:skl2onnx:[Init] 'shape_tensor1', 7, [2]\n",
      "DEBUG:skl2onnx:[Node] 'Reshape' - 'reduce_log_sum_exp_result,shape_tensor1' -> 'reshaped_log_prob' (name='Reshape1')\n",
      "DEBUG:skl2onnx:[Node] 'Sub' - 'sum_result,reshaped_log_prob' -> 'log_prob' (name='Sub')\n",
      "DEBUG:skl2onnx:[Node] 'Exp' - 'log_prob' -> 'voting_proba_0' (name='Exp')\n",
      "DEBUG:skl2onnx:[Node] 'ArrayFeatureExtractor' - 'classes1,argmax_output' -> 'array_feature_extractor_result1' (name='ArrayFeatureExtractor1')\n",
      "DEBUG:skl2onnx:[Node] 'Cast' - 'array_feature_extractor_result1' -> 'cast2_result1' (name='Cast2')\n",
      "DEBUG:skl2onnx:[Init] 'shape_tensor2', 7, [1]\n",
      "DEBUG:skl2onnx:[Node] 'Identity' - 'shape_tensor' -> 'shape_tensor2' (name='shape_tensor2_op')\n",
      "DEBUG:skl2onnx:[Node] 'Reshape' - 'cast2_result1,shape_tensor2' -> 'reshaped_result1' (name='Reshape2')\n",
      "DEBUG:skl2onnx:[Node] 'Cast' - 'reshaped_result1' -> 'label_0' (name='Cast3')\n",
      "DEBUG:skl2onnx:[Conv] end - Operator(type='SklearnMultinomialNB', onnx_name='SklearnMultinomialNB', inputs='X', outputs='label_0,voting_proba_0', raw_operator=MultinomialNB(alpha=0.02))\n",
      "DEBUG:skl2onnx:[Op] update is_evaluated=True for Operator(type='SklearnMultinomialNB', onnx_name='SklearnMultinomialNB', inputs='X', outputs='label_0,voting_proba_0', raw_operator=MultinomialNB(alpha=0.02))\n",
      "DEBUG:skl2onnx:[Var] update is_fed=True for Variable('label_0', 'label_0', type=Int64TensorType(shape=[None])), parent=Operator(type='SklearnMultinomialNB', onnx_name='SklearnMultinomialNB', inputs='X', outputs='label_0,voting_proba_0', raw_operator=MultinomialNB(alpha=0.02))\n",
      "DEBUG:skl2onnx:[Var] update is_fed=True for Variable('voting_proba_0', 'voting_proba_0', type=FloatTensorType(shape=[None, 2])), parent=Operator(type='SklearnMultinomialNB', onnx_name='SklearnMultinomialNB', inputs='X', outputs='label_0,voting_proba_0', raw_operator=MultinomialNB(alpha=0.02))\n",
      "DEBUG:skl2onnx:[Shape2] call infer_types for Operator(type='SklearnSGDClassifier', onnx_name='SklearnSGDClassifier', inputs='X', outputs='label_1,voting_proba_1', raw_operator=SGDClassifier(loss='modified_huber', max_iter=8000, random_state=42, tol=0.0001))\n",
      "DEBUG:skl2onnx:[Shape-a] Operator(type='SklearnSGDClassifier', onnx_name='SklearnSGDClassifier', inputs='X', outputs='label_1,voting_proba_1', raw_operator=SGDClassifier(loss='modified_huber', max_iter=8000, random_state=42, tol=0.0001)) fed 'True' - 'NoneNone'\n",
      "DEBUG:skl2onnx:[Var] update type for Variable('label_1', 'label_1', type=Int64TensorType(shape=[]))\n",
      "DEBUG:skl2onnx:[Shape-b] Operator(type='SklearnSGDClassifier', onnx_name='SklearnSGDClassifier', inputs='X', outputs='label_1,voting_proba_1', raw_operator=SGDClassifier(loss='modified_huber', max_iter=8000, random_state=42, tol=0.0001)) inputs=[Variable('X', 'X', type=FloatTensorType(shape=[None, 380032]))] - outputs=[Variable('label_1', 'label_1', type=Int64TensorType(shape=[None])), Variable('voting_proba_1', 'voting_proba_1', type=FloatTensorType(shape=[None, 2]))]\n",
      "DEBUG:skl2onnx:[Conv] call Operator(type='SklearnSGDClassifier', onnx_name='SklearnSGDClassifier', inputs='X', outputs='label_1,voting_proba_1', raw_operator=SGDClassifier(loss='modified_huber', max_iter=8000, random_state=42, tol=0.0001)) fed 'True' - 'NoneNone'\n",
      "DEBUG:skl2onnx:[Init] 'classes2', 6, (2,)\n",
      "DEBUG:skl2onnx:[Node] 'Identity' - 'classes' -> 'classes2' (name='classes2_op')\n",
      "DEBUG:skl2onnx:[Init] 'coef', 1, (380032, 1)\n",
      "DEBUG:skl2onnx:[Init] 'intercept', 1, (1,)\n",
      "DEBUG:skl2onnx:[Node] 'MatMul' - 'X,coef' -> 'matmul_result1' (name='MatMul1')\n",
      "DEBUG:skl2onnx:[Node] 'Add' - 'matmul_result1,intercept' -> 'score' (name='Add1')\n",
      "DEBUG:skl2onnx:[Init] 'unity', 1, []\n",
      "DEBUG:skl2onnx:[Init] 'constant', 1, []\n",
      "DEBUG:skl2onnx:[Init] 'clip_min', 1, []\n",
      "DEBUG:skl2onnx:[Init] 'clip_max', 1, []\n",
      "DEBUG:skl2onnx:[Node] 'Identity' - 'unity' -> 'clip_max' (name='clip_max_op')\n",
      "DEBUG:skl2onnx:[Node] 'Clip' - 'score,clip_min,clip_max' -> 'clipped_scores' (name='Clip')\n",
      "DEBUG:skl2onnx:[Node] 'Add' - 'clipped_scores,unity' -> 'add_result' (name='Add2')\n",
      "DEBUG:skl2onnx:[Node] 'Div' - 'add_result,constant' -> 'proba' (name='Div')\n",
      "DEBUG:skl2onnx:[Node] 'Sub' - 'unity,proba' -> 'sub_result' (name='Sub1')\n",
      "DEBUG:skl2onnx:[Node] 'Concat' - 'sub_result,proba' -> 'voting_proba_1' (name='Concat')\n",
      "DEBUG:skl2onnx:[Node] 'ArgMax' - 'voting_proba_1' -> 'predicted_label' (name='ArgMax2')\n",
      "DEBUG:skl2onnx:[Node] 'ArrayFeatureExtractor' - 'classes2,predicted_label' -> 'final_label' (name='ArrayFeatureExtractor2')\n",
      "DEBUG:skl2onnx:[Init] 'shape_tensor3', 7, [1]\n",
      "DEBUG:skl2onnx:[Node] 'Identity' - 'shape_tensor' -> 'shape_tensor3' (name='shape_tensor3_op')\n",
      "DEBUG:skl2onnx:[Node] 'Reshape' - 'final_label,shape_tensor3' -> 'reshaped_final_label' (name='Reshape3')\n",
      "DEBUG:skl2onnx:[Node] 'Cast' - 'reshaped_final_label' -> 'label_1' (name='Cast4')\n",
      "DEBUG:skl2onnx:[Conv] end - Operator(type='SklearnSGDClassifier', onnx_name='SklearnSGDClassifier', inputs='X', outputs='label_1,voting_proba_1', raw_operator=SGDClassifier(loss='modified_huber', max_iter=8000, random_state=42, tol=0.0001))\n",
      "DEBUG:skl2onnx:[Op] update is_evaluated=True for Operator(type='SklearnSGDClassifier', onnx_name='SklearnSGDClassifier', inputs='X', outputs='label_1,voting_proba_1', raw_operator=SGDClassifier(loss='modified_huber', max_iter=8000, random_state=42, tol=0.0001))\n",
      "DEBUG:skl2onnx:[Var] update is_fed=True for Variable('label_1', 'label_1', type=Int64TensorType(shape=[None])), parent=Operator(type='SklearnSGDClassifier', onnx_name='SklearnSGDClassifier', inputs='X', outputs='label_1,voting_proba_1', raw_operator=SGDClassifier(loss='modified_huber', max_iter=8000, random_state=42, tol=0.0001))\n",
      "DEBUG:skl2onnx:[Var] update is_fed=True for Variable('voting_proba_1', 'voting_proba_1', type=FloatTensorType(shape=[None, 2])), parent=Operator(type='SklearnSGDClassifier', onnx_name='SklearnSGDClassifier', inputs='X', outputs='label_1,voting_proba_1', raw_operator=SGDClassifier(loss='modified_huber', max_iter=8000, random_state=42, tol=0.0001))\n",
      "DEBUG:skl2onnx:[VarId-a] rename node input 'classes1' into 'classes'\n",
      "DEBUG:skl2onnx:[NodeId-a] remove input: \"classes\"\n",
      "output: \"classes1\"\n",
      "name: \"classes1_op\"\n",
      "op_type: \"Identity\"\n",
      "domain: \"\"\n",
      "\n",
      "DEBUG:skl2onnx:[VarId-a] rename node input 'classes2' into 'classes'\n",
      "DEBUG:skl2onnx:[NodeId-a] remove input: \"classes\"\n",
      "output: \"classes2\"\n",
      "name: \"classes2_op\"\n",
      "op_type: \"Identity\"\n",
      "domain: \"\"\n",
      "\n",
      "DEBUG:skl2onnx:[VarId-a] rename node input 'clip_max' into 'unity'\n",
      "DEBUG:skl2onnx:[NodeId-a] remove input: \"unity\"\n",
      "output: \"clip_max\"\n",
      "name: \"clip_max_op\"\n",
      "op_type: \"Identity\"\n",
      "domain: \"\"\n",
      "\n",
      "DEBUG:skl2onnx:[VarId-a] rename node input 'shape_tensor2' into 'shape_tensor'\n",
      "DEBUG:skl2onnx:[NodeId-a] remove input: \"shape_tensor\"\n",
      "output: \"shape_tensor2\"\n",
      "name: \"shape_tensor2_op\"\n",
      "op_type: \"Identity\"\n",
      "domain: \"\"\n",
      "\n",
      "DEBUG:skl2onnx:[VarId-a] rename node input 'shape_tensor3' into 'shape_tensor'\n",
      "DEBUG:skl2onnx:[NodeId-a] remove input: \"shape_tensor\"\n",
      "output: \"shape_tensor3\"\n",
      "name: \"shape_tensor3_op\"\n",
      "op_type: \"Identity\"\n",
      "domain: \"\"\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved! Input shape: [batch_size, 380032]\n",
      "Output: probabilities [batch_size, 2]\n"
     ]
    }
   ],
   "source": [
    "from skl2onnx import to_onnx\n",
    "output_dir = Path(\"../model_artifacts\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save vectorizer in both formats:\n",
    "# 1. JSON-wrapped format for Python (with metadata)\n",
    "vectorizer.save(output_dir / \"tfidf_vectorizer.json\")\n",
    "\n",
    "# 2. Raw bincode format for Rust (no JSON wrapper)\n",
    "vectorizer.save_raw_bincode(output_dir / \"tfidf_vectorizer.bin\")\n",
    "\n",
    "# Convert to ONNX\n",
    "# Disable ZipMap to output probabilities as a 2D tensor [batch_size, num_classes]\n",
    "onx = to_onnx(\n",
    "    ensemble,\n",
    "    X_train_tfidf[:1].astype(np.float32).toarray(),  # Sample for shape inference\n",
    "    target_opset=15,\n",
    "    options={\n",
    "        type(ensemble): {'zipmap': False}  # Output probabilities as tensor, not dict\n",
    "    }\n",
    ")\n",
    "model_name = output_dir / \"slop-classifier.onnx\"\n",
    "with model_name.open(\"wb\") as f:\n",
    "    f.write(onx.SerializeToString())\n",
    "\n",
    "print(f\"Model saved! Input shape: [batch_size, {X_train_tfidf.shape[1]}]\")\n",
    "print(f\"Output: probabilities [batch_size, 2]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03fdc24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "onnx_model = onnx.load(model_name)\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02aa8253",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 21:54:03.451 python[61784:8363778] 2025-11-24 21:54:03.449128 [W:onnxruntime:, graph.cc:4885 CleanUnusedInitializersAndNodeArgs] Removing initializer 'classes_ind'. It is not used by any node and should be removed from the model.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy\n",
    "import onnxruntime as rt\n",
    "\n",
    "sess = rt.InferenceSession(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52d8cbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'X'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_name = sess.get_inputs()[0].name\n",
    "input_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05a6e9c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse array of dtype 'float64'\n",
       "\twith 342 stored elements and shape (1, 380032)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a27e200d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse array of dtype 'float64'\n",
       "\twith 694 stored elements and shape (2, 380032)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input = X_train_tfidf[:2]#.todense()\n",
    "test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0eec665d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.predict(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dce7239c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1, 0], dtype=int64), array([[9.1592313e-17, 1.0000000e+00],\n",
      "       [9.7694218e-01, 2.3057826e-02]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "input_name = sess.get_inputs()[0].name\n",
    "# pred_onx = sess.run(None, {input_name: X_test.astype(numpy.float32)})[0]\n",
    "\n",
    "pred_onx = sess.run(None, {input_name: X_train_tfidf[:2].astype(np.float32).toarray()})\n",
    "print(pred_onx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22b61dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "is-it-slop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

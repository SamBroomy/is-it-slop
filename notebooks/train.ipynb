{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from typing import Protocol\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "import tiktoken\n",
    "from __init__ import PLOT_DIR, RETRAIN_VECTORIZER, RETRAINED_MODEL_VERSION, SEED, VECTORIZER_BIN_PATH, df_test, df_train\n",
    "from is_it_slop_preprocessing import TfidfVectorizer, VectorizerParams, __version__\n",
    "from loguru import logger\n",
    "from matplotlib import gridspec\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.stats import entropy, gaussian_kde\n",
    "from skl2onnx import to_onnx\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.calibration import CalibratedClassifierCV, LinearSVC, calibration_curve\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import (\n",
    "    ConfusionMatrixDisplay,\n",
    "    DetCurveDisplay,\n",
    "    RocCurveDisplay,\n",
    "    accuracy_score,\n",
    "    auc,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    matthews_corrcoef,\n",
    "    precision_recall_curve,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Python random\n",
    "random.seed(SEED)\n",
    "\n",
    "np.random.default_rng(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "os.environ[\"ORT_DETERMINISTIC\"] = \"1\"\n",
    "\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "mlflow.set_experiment(\"is-it-slop-training-pipeline\")\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.getLogger(\"is_it_slop_preprocessing\").setLevel(logging.DEBUG)\n",
    "logging.getLogger(\"matplotlib\").setLevel(logging.WARNING)\n",
    "logging.getLogger(\"matplotlib.font_manager\").setLevel(logging.WARNING)\n",
    "print(f\"Bindings version: {__version__}\")\n",
    "print(f\"Pipeline model version output: {RETRAINED_MODEL_VERSION}\")\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.dpi\"] = 600\n",
    "plt.rcParams[\"savefig.dpi\"] = 1200\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "\n",
    "print(\"Vectorizer exists:\", VECTORIZER_BIN_PATH.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.select(\"text\").collect().to_series().to_numpy()\n",
    "y_train = df_train.select(\"label\").collect().to_series().to_numpy()\n",
    "\n",
    "X_test = df_test.select(\"text\").collect().to_series().to_numpy()\n",
    "y_test = df_test.select(\"label\").collect().to_series().to_numpy()\n",
    "\n",
    "total_samples = len(X_train) + len(X_test)\n",
    "logger.info(f\"Total samples: {total_samples}\")\n",
    "logger.info(f\"Training samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
    "\n",
    "# Start MLflow run\n",
    "mlflow.start_run()\n",
    "\n",
    "# Log dataset info\n",
    "mlflow.log_param(\"total_samples\", total_samples)\n",
    "mlflow.log_param(\"train_samples\", len(X_train))\n",
    "mlflow.log_param(\"test_samples\", len(X_test))\n",
    "mlflow.log_param(\"preprocessing_version\", __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Fitting Rust TF-IDF vectorizer...\")\n",
    "t1 = time.time()\n",
    "\n",
    "if RETRAIN_VECTORIZER or not VECTORIZER_BIN_PATH.exists():\n",
    "    logger.info(\"Training new Vectorizer\")\n",
    "    params = VectorizerParams(ngram_range=(2, 4), min_df=50, max_df=0.8)\n",
    "\n",
    "    # Log vectorizer params\n",
    "    mlflow.log_param(\"ngram_range\", f\"{params.ngram_range}\")\n",
    "    mlflow.log_param(\"min_df\", params.min_df)\n",
    "    mlflow.log_param(\"max_df\", params.max_df)\n",
    "    mlflow.log_param(\"retrain_vectorizer\", True)\n",
    "\n",
    "    (vectorizer, X_train_tfidf) = TfidfVectorizer.fit_transform(X_train, params)\n",
    "    logger.info(\n",
    "        f\"Fitted vectorizer and transformed training data {X_train_tfidf.shape} in {time.time() - t1:.2f} seconds\"\n",
    "    )\n",
    "    t2 = time.time()\n",
    "else:\n",
    "    logger.info(\"Loading Pre-trained Vectorizer\")\n",
    "\n",
    "    vectorizer = TfidfVectorizer.load(VECTORIZER_BIN_PATH)\n",
    "    mlflow.log_param(\"retrain_vectorizer\", False)\n",
    "    logger.info(f\"Loaded vectorizer in {time.time() - t1:.2f} seconds\")\n",
    "    t2 = time.time()\n",
    "    X_train_tfidf = vectorizer.transform(X_train)\n",
    "    logger.info(f\"Transformed training data {X_train_tfidf.shape} in {time.time() - t2:.2f} seconds\")\n",
    "    t2 = time.time()\n",
    "logger.info(\"Transforming test data...\")\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "logger.info(f\"Transformed test data {X_test_tfidf.shape} in {time.time() - t2:.2f} seconds\")\n",
    "logger.info(f\"Train Feature matrix: {X_train_tfidf.shape}\")\n",
    "sparsity = 100 * (1 - X_train_tfidf.nnz / np.prod(X_train_tfidf.shape))  # pyright: ignore[reportCallIssue, reportArgumentType]\n",
    "logger.info(f\"Sparsity: {sparsity:.2f}%\")\n",
    "\n",
    "# Log feature matrix metrics\n",
    "mlflow.log_metric(\"n_features\", X_train_tfidf.shape[1])  # pyright: ignore[reportOptionalSubscript]\n",
    "mlflow.log_metric(\"sparsity_percent\", sparsity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ensemble\n",
    "logger.info(\"Training ensemble...\")\n",
    "\n",
    "nb = MultinomialNB(alpha=0.01)\n",
    "\n",
    "# cn = ComplementNB(alpha=0.01)\n",
    "\n",
    "sgd = SGDClassifier(\n",
    "    loss=\"modified_huber\",\n",
    "    penalty=\"l2\",\n",
    "    alpha=0.00005,\n",
    "    class_weight=\"balanced\",\n",
    "    early_stopping=True,\n",
    "    max_iter=8000,\n",
    "    tol=1e-4,\n",
    "    random_state=SEED,\n",
    "    learning_rate=\"optimal\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    penalty=\"l2\", C=1.0, solver=\"saga\", max_iter=1000, class_weight=\"balanced\", random_state=SEED, n_jobs=-1\n",
    ")\n",
    "\n",
    "# LinearSVC - very fast, needs calibration for probabilities\n",
    "svc = LinearSVC(\n",
    "    C=1.0,\n",
    "    loss=\"squared_hinge\",  # Good for sparse data\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=SEED,\n",
    ")\n",
    "# Wrap for probability calibration (needed for ensemble voting='soft')\n",
    "svc_calibrated = CalibratedClassifierCV(svc, cv=5, method=\"sigmoid\")\n",
    "\n",
    "estimators: list[tuple[str, BaseEstimator, float]] = [\n",
    "    (\"sgd\", sgd, 0.25),\n",
    "    (\"logreg\", logreg, 0.30),\n",
    "    (\"svc\", svc_calibrated, 0.30),\n",
    "    (\"nb\", nb, 0.15),\n",
    "    # (\"cnb\", cn, 0.05),\n",
    "]\n",
    "voting = \"soft\"\n",
    "\n",
    "assert abs(sum(weight for _, _, weight in estimators) - 1.0) < 1e-6, \"Weights must sum to 1.0\"  # noqa: S101\n",
    "\n",
    "mlflow.log_param(\"ensemble_estimators\", [name for name, _, _ in estimators])\n",
    "mlflow.log_param(\"ensemble_weights\", [weight for _, _, weight in estimators])\n",
    "mlflow.log_param(\"model_type\", \"VotingClassifier\")\n",
    "mlflow.log_param(\"voting\", voting)\n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[(name, model) for name, model, _ in estimators],\n",
    "    weights=[weight for _, _, weight in estimators],\n",
    "    voting=voting,\n",
    "    n_jobs=-1,\n",
    "    flatten_transform=False,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Retrain\n",
    "ensemble.fit(X_train_tfidf, y_train)\n",
    "# This is just a list but to save to onnx we need it as a numpy array\n",
    "ensemble.weights = np.array(ensemble.weights)  # pyright: ignore[reportAttributeAccessIssue]\n",
    "\n",
    "# Use a Protocol or Union type for classifiers with predict_proba\n",
    "\n",
    "\n",
    "class ProbabilisticClassifier(Protocol):\n",
    "    def predict_proba(self, X) -> np.ndarray: ...  # noqa: ANN001\n",
    "    def predict(self, X) -> np.ndarray: ...  # noqa: ANN001\n",
    "    def fit(self, X, y) -> \"ProbabilisticClassifier\": ...  # noqa: ANN001\n",
    "    @property\n",
    "    def coef_(self) -> np.ndarray: ...\n",
    "\n",
    "\n",
    "models: dict[str, ProbabilisticClassifier] = {\n",
    "    \"sgd\": ensemble.estimators_[0],\n",
    "    \"logreg\": ensemble.estimators_[1],\n",
    "    \"svc\": ensemble.estimators_[2],\n",
    "    \"nb\": ensemble.estimators_[3],\n",
    "    # \"cnb\": ensemble.estimators_[4],\n",
    "    \"ensemble\": ensemble,\n",
    "}  # pyright: ignore[reportAssignmentType]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X_train_tfidf.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs = ensemble.predict_proba(X_test_tfidf)[:, 1]\n",
    "y_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_curve_analysis(\n",
    "    X_train_tfidf: csr_matrix, y_train: np.ndarray, X_test_tfidf: csr_matrix, y_test: np.ndarray, models: dict\n",
    ") -> None:\n",
    "    dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "    dummy.fit(X_train_tfidf, y_train)\n",
    "    models_with_dummy = models.copy()\n",
    "    models_with_dummy[\"dummy\"] = dummy\n",
    "\n",
    "    _fig, [ax_roc, ax_det] = plt.subplots(1, 2, figsize=(11, 5))\n",
    "\n",
    "    ax_roc.set_title(\"Receiver Operating Characteristic (ROC) curves\")\n",
    "    ax_det.set_title(\"Detection Error Tradeoff (DET) curves\")\n",
    "\n",
    "    ax_roc.grid(linestyle=\"--\")\n",
    "    ax_det.grid(linestyle=\"--\")\n",
    "\n",
    "    for name, clf in models_with_dummy.items():\n",
    "        (color, linestyle) = (\"blue\", \"-\") if name == \"dummy\" else (None, None)\n",
    "        y_pred_ = clf.predict_proba(X_test_tfidf)[:, 1]\n",
    "        # y_pred = clf.predict_proba(X_test_tfidf)[:, 1] if name != \"dummy\" else clf.predict(X_test_tfidf)\n",
    "\n",
    "        RocCurveDisplay.from_predictions(\n",
    "            y_test, y_pred_, ax=ax_roc, name=name, curve_kwargs={\"color\": color, \"linestyle\": linestyle}\n",
    "        )\n",
    "        DetCurveDisplay.from_predictions(y_test, y_pred_, ax=ax_det, name=name, color=color, linestyle=linestyle)\n",
    "    plt.legend()\n",
    "    plot_path = PLOT_DIR / \"roc_det_curve_analysis.png\"\n",
    "    plt.savefig(plot_path, bbox_inches=\"tight\")\n",
    "    mlflow.log_artifact(str(plot_path))\n",
    "\n",
    "\n",
    "roc_curve_analysis(X_train_tfidf, y_train, X_test_tfidf, y_test, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) use precision-recall curve for exact best F1 (thresholds length differs)\n",
    "\n",
    "\n",
    "def compute_best_thresholds(y_test: np.ndarray, probs: np.ndarray) -> tuple[float, float]:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, probs)\n",
    "    plt.plot(thresholds, precision[:-1], label=\"Precision\", linewidth=2, color=\"#3498db\")\n",
    "    plt.plot(thresholds, recall[:-1], label=\"Recall\", linewidth=2, color=\"#e74c3c\")\n",
    "\n",
    "    f1_scores = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-10)\n",
    "    plt.plot(thresholds, f1_scores, label=\"F1 Score\", linewidth=2, color=\"#2ecc71\", linestyle=\"--\")\n",
    "\n",
    "    best_idx = np.nanargmax(f1_scores)\n",
    "    best_threshold = thresholds[best_idx]\n",
    "    logger.info(f\"Best threshold (Precision-Recall curve): {best_threshold:.4f} with F1: {f1_scores[best_idx]:.4f}\")\n",
    "\n",
    "    false_positive_rate, true_positive_rate, roc_thresholds = roc_curve(y_test, probs)\n",
    "    youden = true_positive_rate - false_positive_rate\n",
    "    best_idx_roc = np.argmax(youden)\n",
    "    best_threshold_roc = roc_thresholds[best_idx_roc]\n",
    "    logger.info(\n",
    "        f\"Best threshold (Youden's J statistic): {best_threshold_roc:.4f} with Youden: {youden[best_idx_roc]:.4f}\"\n",
    "    )\n",
    "    aoc_score = auc(false_positive_rate, true_positive_rate)\n",
    "    logger.info(f\"ROC AUC: {aoc_score:.4f}\")\n",
    "    plt.plot(roc_thresholds, youden, label=\"Youden's J Statistic\", linewidth=2, color=\"#9b59b6\", linestyle=\":\")\n",
    "\n",
    "    plt.axvline(best_threshold, color=\"#2ecc71\", linestyle=\"--\", label=f\"Best Threshold: {best_threshold:.4f}\")\n",
    "    plt.axvline(\n",
    "        best_threshold_roc, color=\"#9b59b6\", linestyle=\"--\", label=f\"Best Youden Threshold: {best_threshold_roc:.4f}\"\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"Precision, Recall, and F1 Score vs. Threshold\")\n",
    "    plt.legend()\n",
    "    plt.grid(visible=True, alpha=0.3)\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plot_path = PLOT_DIR / \"precision_recall_f1_thresholds.png\"\n",
    "    plt.savefig(plot_path, bbox_inches=\"tight\")\n",
    "    mlflow.log_artifact(str(plot_path))\n",
    "\n",
    "    return best_threshold, best_threshold_roc\n",
    "\n",
    "\n",
    "best_threshold, best_threshold_roc = compute_best_thresholds(y_test, y_probs)\n",
    "\n",
    "# Log thresholds\n",
    "mlflow.log_metric(\"best_threshold_f1\", best_threshold)\n",
    "mlflow.log_metric(\"best_threshold_youden\", best_threshold_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_probs >= best_threshold).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 is best, 0 is random, -1 is worst\n",
    "test_mcc = matthews_corrcoef(y_test, y_pred)\n",
    "logger.info(f\"Validation MCC: {test_mcc:.4f}\")\n",
    "\n",
    "test_auc: float = roc_auc_score(y_test, y_pred)  # pyright: ignore[reportAssignmentType]\n",
    "logger.info(f\"Validation AUC: {test_auc:.4f}\")\n",
    "accuracy: float = accuracy_score(y_test, y_pred)  # pyright: ignore[reportAssignmentType]\n",
    "logger.info(f\"Accuracy:   {accuracy:.4f}\")\n",
    "precision: float = precision_score(y_test, y_pred)  # pyright: ignore[reportAssignmentType]\n",
    "logger.info(f\"Precision:  {precision:.4f}\")\n",
    "recall: float = recall_score(y_test, y_pred)  # pyright: ignore[reportAssignmentType]\n",
    "logger.info(f\"Recall:     {recall:.4f}\")\n",
    "f1: float = f1_score(y_test, y_pred)  # pyright: ignore[reportAssignmentType]\n",
    "logger.info(f\"F1 Score:   {f1:.4f}\")\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "logger.info(f\"TP: {tp}, FP: {fp}, TN: {tn}, FN: {fn}\")\n",
    "logger.info(\"Confusion Matrix:\")\n",
    "logger.info(\"              Predicted\")\n",
    "logger.info(\"                 0      1\")\n",
    "logger.info(f\"Actual  0    {tn:5d}  {fp:5d}\")\n",
    "logger.info(f\"        1    {fn:5d}  {tp:5d}\")\n",
    "dis = ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
    "plot_path = PLOT_DIR / \"confusion_matrix.png\"\n",
    "dis.figure_.savefig(plot_path, bbox_inches=\"tight\")\n",
    "mlflow.log_artifact(str(plot_path))\n",
    "\n",
    "# Log all metrics to MLflow\n",
    "mlflow.log_metric(\"test_mcc\", test_mcc)\n",
    "mlflow.log_metric(\"test_auc\", test_auc)\n",
    "mlflow.log_metric(\"accuracy\", accuracy)\n",
    "mlflow.log_metric(\"precision\", precision)\n",
    "mlflow.log_metric(\"recall\", recall)\n",
    "mlflow.log_metric(\"f1_score\", f1)\n",
    "mlflow.log_metric(\"true_positives\", int(tp))\n",
    "mlflow.log_metric(\"false_positives\", int(fp))\n",
    "mlflow.log_metric(\"true_negatives\", int(tn))\n",
    "mlflow.log_metric(\"false_negatives\", int(fn))\n",
    "\n",
    "# 2025-12-01 12:46:23.856 | INFO     | __main__:<module>:3 - Validation MCC: 0.9267\n",
    "# 2025-12-01 12:46:23.860 | INFO     | __main__:<module>:6 - Validation AUC: 0.9634\n",
    "# 2025-12-01 12:46:23.862 | INFO     | __main__:<module>:8 - Accuracy:   0.9634\n",
    "# 2025-12-01 12:46:23.866 | INFO     | __main__:<module>:10 - Precision:  0.9660\n",
    "# 2025-12-01 12:46:23.871 | INFO     | __main__:<module>:12 - Recall:     0.9613\n",
    "# 2025-12-01 12:46:23.878 | INFO     | __main__:<module>:14 - F1 Score:   0.9636\n",
    "# 2025-12-01 12:46:23.880 | INFO     | __main__:<module>:17 - TP: 22074, FP: 778, TN: 21742, FN: 888\n",
    "# 2025-12-01 12:46:23.881 | INFO     | __main__:<module>:18 - Confusion Matrix:\n",
    "# 2025-12-01 12:46:23.881 | INFO     | __main__:<module>:19 -               Predicted\n",
    "# 2025-12-01 12:46:23.882 | INFO     | __main__:<module>:20 -                  0      1\n",
    "# 2025-12-01 12:46:23.882 | INFO     | __main__:<module>:21 - Actual  0    21742    778\n",
    "# 2025-12-01 12:46:23.883 | INFO     | __main__:<module>:22 -         1      888  22074\n",
    "\n",
    "\n",
    "# 2025-12-01 12:58:52.663 | INFO     | __main__:<module>:3 - Validation MCC: 0.9284\n",
    "# 2025-12-01 12:58:52.668 | INFO     | __main__:<module>:6 - Validation AUC: 0.9642\n",
    "# 2025-12-01 12:58:52.670 | INFO     | __main__:<module>:8 - Accuracy:   0.9642\n",
    "# 2025-12-01 12:58:52.676 | INFO     | __main__:<module>:10 - Precision:  0.9685\n",
    "# 2025-12-01 12:58:52.682 | INFO     | __main__:<module>:12 - Recall:     0.9603\n",
    "# 2025-12-01 12:58:52.686 | INFO     | __main__:<module>:14 - F1 Score:   0.9644\n",
    "# 2025-12-01 12:58:52.688 | INFO     | __main__:<module>:17 - TP: 22051, FP: 717, TN: 21803, FN: 911\n",
    "# 2025-12-01 12:58:52.689 | INFO     | __main__:<module>:18 - Confusion Matrix:\n",
    "# 2025-12-01 12:58:52.689 | INFO     | __main__:<module>:19 -               Predicted\n",
    "# 2025-12-01 12:58:52.689 | INFO     | __main__:<module>:20 -                  0      1\n",
    "# 2025-12-01 12:58:52.689 | INFO     | __main__:<module>:21 - Actual  0    21803    717\n",
    "# 2025-12-01 12:58:52.690 | INFO     | __main__:<module>:22 -         1      911  22051"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from __init__ import CLASSIFICATION_THRESHOLD_PATH, MODEL_ONNX_PATH, VECTORIZER_JSON_PATH\n",
    "from onnxruntime.transformers.onnx_model import OnnxModel\n",
    "\n",
    "# Save vectorizer in both formats:\n",
    "# 1. JSON-wrapped format for Python (with metadata)\n",
    "vectorizer.save(VECTORIZER_JSON_PATH)\n",
    "logger.info(f\"Saved json vectorizer to {VECTORIZER_JSON_PATH}\")\n",
    "# 2. Raw bincode format for Rust (no JSON wrapper)\n",
    "vectorizer.save(VECTORIZER_BIN_PATH)\n",
    "logger.info(f\"Saved binary vectorizer to {VECTORIZER_BIN_PATH}\")\n",
    "\n",
    "Path(CLASSIFICATION_THRESHOLD_PATH).write_text(str(best_threshold), encoding=\"utf-8\")\n",
    "logger.info(f\"Saved classification threshold to {CLASSIFICATION_THRESHOLD_PATH}\")\n",
    "# Convert to ONNX\n",
    "# Disable ZipMap to output probabilities as a 2D tensor [batch_size, num_classes]\n",
    "onx: onnx.ModelProto = to_onnx(\n",
    "    ensemble,\n",
    "    X_train_tfidf[:1].toarray(),  # Sample for shape inference\n",
    "    options={\n",
    "        type(ensemble): {\"zipmap\": False}  # Output probabilities as tensor, not dict\n",
    "    },\n",
    ")  # pyright: ignore[reportAssignmentType]\n",
    "onnx.checker.check_model(onx, full_check=True)\n",
    "\n",
    "\n",
    "# with MODEL_ONNX_PATH.open(\"wb\") as f:\n",
    "#     f.write(onx.SerializeToString())#deterministic=True))\n",
    "# logger.info(f\"Saved ONNX model to {MODEL_ONNX_PATH}\")\n",
    "\n",
    "# onnx_model = onnx.load(MODEL_ONNX_PATH)\n",
    "\n",
    "\n",
    "# To get rid of the following errors we need to prune the graph\n",
    "# \"CleanUnusedInitializersAndNodeArgs] Removing initializer 'classes_ind'. It is not used by any node and should be removed from the model\"\n",
    "onnx_model = OnnxModel(onx)\n",
    "onnx_model.prune_graph()\n",
    "onnx_model.save_model_to_file(MODEL_ONNX_PATH)\n",
    "\n",
    "\n",
    "# Log artifacts to MLflow\n",
    "mlflow.log_artifact(str(MODEL_ONNX_PATH))\n",
    "mlflow.log_artifact(str(VECTORIZER_BIN_PATH))\n",
    "mlflow.log_artifact(str(VECTORIZER_JSON_PATH))\n",
    "mlflow.log_artifact(str(CLASSIFICATION_THRESHOLD_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as rt\n",
    "\n",
    "sess = rt.InferenceSession(MODEL_ONNX_PATH, providers=[\"CPUExecutionProvider\"])\n",
    "\n",
    "input_name = sess.get_inputs()[0].name\n",
    "\n",
    "test_input = X_train_tfidf[:2]  # .astype(np.float64)  # .todense()\n",
    "\n",
    "input_name = sess.get_inputs()[0].name\n",
    "\n",
    "pred_onx = sess.run(None, {input_name: test_input.toarray()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred = ensemble.predict_proba(test_input)\n",
    "model_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(pred_onx[1], model_pred)  # pyright: ignore[reportArgumentType]  # noqa: S101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediction_distributions(X_test_tfidf: csr_matrix, y_test: np.ndarray, models: dict) -> None:\n",
    "    fig = plt.figure(figsize=(16, 18))\n",
    "    gs = gridspec.GridSpec(3, 2, height_ratios=[1, 1, 1.2])\n",
    "\n",
    "    axes = [\n",
    "        fig.add_subplot(gs[0, 0]),\n",
    "        fig.add_subplot(gs[0, 1]),\n",
    "        fig.add_subplot(gs[1, 0]),\n",
    "        fig.add_subplot(gs[1, 1]),\n",
    "        fig.add_subplot(gs[2, :]),  # This spans both columns in the last row\n",
    "    ]\n",
    "    # fig, axes = plt.subplots(3, 2, figsize=(16, 18))\n",
    "    # axes = axes.flatten()\n",
    "\n",
    "    for idx, (name, model) in enumerate(models.items()):\n",
    "        probs_ = model.predict_proba(X_test_tfidf)[:, 1]\n",
    "        ax = axes[idx]\n",
    "\n",
    "        # Separate by true label\n",
    "        human_probs = probs_[y_test == 0]\n",
    "        ai_probs = probs_[y_test == 1]\n",
    "\n",
    "        ax.hist(human_probs, bins=50, alpha=0.5, label=\"Human (true)\", color=\"blue\")\n",
    "        ax.hist(ai_probs, bins=50, alpha=0.5, label=\"AI (true)\", color=\"red\")\n",
    "        ax.set_xlabel(\"Predicted Probability (AI class)\")\n",
    "        ax.set_ylabel(\"Count\")\n",
    "        ax.set_title(f\"{name.upper()} - Prediction Distribution\")\n",
    "        ax.legend()\n",
    "        ax.set_yscale(\"log\")  # Log scale to see tails\n",
    "        human_max = human_probs.max()\n",
    "        ai_min = ai_probs.min()\n",
    "        print(f\"{name:10s} - Human max prob: {human_max:.4f}, AI min prob: {ai_min:.4f}\")\n",
    "        if human_max < ai_min:\n",
    "            print(f\"           -> PERFECT SEPARATION! Gap: {ai_min - human_max:.4f}\")\n",
    "        else:\n",
    "            print(f\"           -> Overlap region: {human_max - ai_min:.4f}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plot_path = PLOT_DIR / \"model_prediction_distributions.png\"\n",
    "    plt.savefig(plot_path, bbox_inches=\"tight\")\n",
    "    mlflow.log_artifact(str(plot_path))\n",
    "\n",
    "\n",
    "plot_prediction_distributions(X_test_tfidf, y_test, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_calibration_curves(X_test_tfidf: csr_matrix, y_test: np.ndarray, models: dict) -> None:\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    colors = plt.cm.get_cmap(\"Accent\", len(models))\n",
    "\n",
    "    for idx, (name, model) in enumerate(models.items()):\n",
    "        prob_true, prob_pred = calibration_curve(y_test, model.predict_proba(X_test_tfidf)[:, 1], n_bins=10)\n",
    "        plt.plot(prob_pred, prob_true, marker=\"o\", label=name.upper(), color=colors(idx))\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Perfect Calibration\")\n",
    "    plt.xlabel(\"Mean Predicted Probability\")\n",
    "    plt.ylabel(\"Fraction of Positives\")\n",
    "    plt.title(\"Calibration Curves (All Models)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plot_path = PLOT_DIR / \"calibration_curves.png\"\n",
    "    plt.savefig(plot_path, bbox_inches=\"tight\")\n",
    "    mlflow.log_artifact(str(plot_path))\n",
    "\n",
    "\n",
    "plot_calibration_curves(X_test_tfidf, y_test, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_boundary_analysis(\n",
    "    X_tfidf: csr_matrix | np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    y_pred_proba: np.ndarray,\n",
    "    sample_size: int = 3000,\n",
    "    decision_threshold: float = 0.5,\n",
    ") -> None:\n",
    "    \"\"\"Analyze model decision boundary characteristics.\n",
    "\n",
    "    Reveals:\n",
    "    - Confidence distribution\n",
    "    - Calibration quality\n",
    "    - Uncertainty regions\n",
    "    \"\"\"\n",
    "    # Sample for performance\n",
    "    if len(y) > sample_size:\n",
    "        rng = np.random.default_rng(SEED)\n",
    "        indices = rng.choice(len(y), sample_size, replace=False)\n",
    "        X_sample = X_tfidf[indices]\n",
    "        y_sample = y[indices]\n",
    "        proba_sample = y_pred_proba[indices]\n",
    "    else:\n",
    "        X_sample = X_tfidf\n",
    "        y_sample = y\n",
    "        proba_sample = y_pred_proba\n",
    "\n",
    "    _fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "    # 1. Confidence distribution by class\n",
    "    ax = axes[0, 0]\n",
    "\n",
    "    human_probs = proba_sample[y_sample == 0, 1]\n",
    "    ai_probs = proba_sample[y_sample == 1, 1]\n",
    "\n",
    "    ax.hist(human_probs, bins=50, alpha=0.6, color=\"#3498db\", label=\"Human (true)\", density=True)\n",
    "    ax.hist(ai_probs, bins=50, alpha=0.6, color=\"#e74c3c\", label=\"AI (true)\", density=True)\n",
    "    ax.axvline(x=decision_threshold, color=\"black\", linestyle=\"--\", linewidth=2, label=\"Threshold\")\n",
    "    ax.set_xlabel(\"Predicted Probability (AI class)\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.set_title(\"Prediction Distribution by True Class\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # 2. Confidence distribution (log scale)\n",
    "    ax = axes[0, 1]\n",
    "\n",
    "    ax.hist(human_probs, bins=50, alpha=0.6, color=\"#3498db\", label=\"Human (true)\", density=True)\n",
    "    ax.hist(ai_probs, bins=50, alpha=0.6, color=\"#e74c3c\", label=\"AI (true)\", density=True)\n",
    "    ax.axvline(x=decision_threshold, color=\"black\", linestyle=\"--\", linewidth=2)\n",
    "    ax.set_xlabel(\"Predicted Probability (AI class)\")\n",
    "    ax.set_ylabel(\"Density (log scale)\")\n",
    "    ax.set_title(\"Prediction Distribution (Log Scale)\")\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # 3. Calibration curve\n",
    "    ax = axes[0, 2]\n",
    "\n",
    "    prob_true, prob_pred = calibration_curve(y_sample, proba_sample[:, 1], n_bins=10, strategy=\"uniform\")\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], \"k--\", linewidth=2, label=\"Perfect Calibration\")\n",
    "    ax.plot(prob_pred, prob_true, marker=\"o\", linewidth=2, markersize=8, color=\"#e67e22\", label=\"Model\")\n",
    "    ax.set_xlabel(\"Mean Predicted Probability\")\n",
    "    ax.set_ylabel(\"Fraction of Positives\")\n",
    "    ax.set_title(\"Calibration Curve (Reliability Diagram)\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # 4. Uncertainty vs correctness\n",
    "    ax = axes[1, 0]\n",
    "\n",
    "    # Calculate uncertainty (distance from decision boundary)\n",
    "    uncertainty = np.abs(proba_sample[:, 1] - decision_threshold)\n",
    "    correct = (proba_sample[:, 1] > decision_threshold) == y_sample\n",
    "\n",
    "    correct_uncertainty = uncertainty[correct]\n",
    "    incorrect_uncertainty = uncertainty[~correct]\n",
    "\n",
    "    ax.hist(correct_uncertainty, bins=30, alpha=0.6, color=\"#2ecc71\", label=\"Correct\", density=True)\n",
    "    ax.hist(incorrect_uncertainty, bins=30, alpha=0.6, color=\"#e74c3c\", label=\"Incorrect\", density=True)\n",
    "    ax.set_xlabel(f\"Uncertainty (distance from threshold {decision_threshold:.4f})\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.set_title(\"Uncertainty Distribution by Correctness\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # 5. Precision-Recall by threshold\n",
    "    ax = axes[1, 1]\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_sample, proba_sample[:, 1])\n",
    "\n",
    "    ax.plot(thresholds, precision[:-1], label=\"Precision\", linewidth=2, color=\"#3498db\")\n",
    "    ax.plot(thresholds, recall[:-1], label=\"Recall\", linewidth=2, color=\"#e74c3c\")\n",
    "\n",
    "    # F1 score\n",
    "    f1_scores = 2 * (precision[:-1] * recall[:-1]) / (precision[:-1] + recall[:-1] + 1e-10)\n",
    "    ax.plot(thresholds, f1_scores, label=\"F1 Score\", linewidth=2, color=\"#2ecc71\", linestyle=\"--\")\n",
    "\n",
    "    ax.axvline(x=decision_threshold, color=\"black\", linestyle=\"--\", linewidth=1, alpha=0.5)\n",
    "    ax.set_xlabel(\"Threshold\")\n",
    "    ax.set_ylabel(\"Score\")\n",
    "    ax.set_title(\"Precision, Recall, F1 vs Threshold\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_ylim([0, 1])\n",
    "\n",
    "    # 6. Confusion regions in 2D projection\n",
    "    ax = axes[1, 2]\n",
    "\n",
    "    # Use first 2 SVD components for visualization\n",
    "    print(\"Computing 2D projection for decision boundary...\")\n",
    "    svd_2d = TruncatedSVD(n_components=2, random_state=SEED)\n",
    "    X_2d = svd_2d.fit_transform(X_sample)\n",
    "\n",
    "    # Create meshgrid\n",
    "    x_min, x_max = X_2d[:, 0].min() - 1, X_2d[:, 0].max() + 1\n",
    "    y_min, y_max = X_2d[:, 1].min() - 1, X_2d[:, 1].max() + 1\n",
    "    _xx, _yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "\n",
    "    # Plot decision regions\n",
    "    scatter = ax.scatter(\n",
    "        X_2d[:, 0],\n",
    "        X_2d[:, 1],\n",
    "        c=proba_sample[:, 1],\n",
    "        cmap=\"RdYlBu_r\",\n",
    "        s=20,\n",
    "        alpha=0.6,\n",
    "        edgecolors=\"black\",\n",
    "        linewidth=0.5,\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"First SVD Component\")\n",
    "    ax.set_ylabel(\"Second SVD Component\")\n",
    "    ax.set_title(\"Decision Space (2D Projection)\")\n",
    "\n",
    "    cbar = plt.colorbar(scatter, ax=ax)\n",
    "    cbar.set_label(\"Predicted Prob (AI)\")\n",
    "    plt.tight_layout()\n",
    "    plot_path = PLOT_DIR / \"decision_boundary_analysis.png\"\n",
    "    plt.savefig(plot_path, bbox_inches=\"tight\")\n",
    "    mlflow.log_artifact(str(plot_path))\n",
    "\n",
    "\n",
    "decision_boundary_analysis(\n",
    "    X_test_tfidf, y_test, ensemble.predict_proba(X_test_tfidf), decision_threshold=best_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_features_by_ngram_length(vectorizer: TfidfVectorizer, models, top_n: int = 20) -> None:  # noqa: ANN001\n",
    "\n",
    "    vocab = vectorizer.vocabulary\n",
    "\n",
    "    for name, model in models.items():\n",
    "        print(f\"\\n\\nFeature analysis for {name.upper()}:\")\n",
    "\n",
    "        try:\n",
    "            coefs = model.coef_[0]\n",
    "        except AttributeError:\n",
    "            print(f\"Model {name} does not have coef_ attribute, skipping feature analysis.\")\n",
    "            continue\n",
    "        # Get top features for each class\n",
    "        top_ai_indices = np.argsort(coefs)[-top_n:][::-1]\n",
    "        top_human_indices = np.argsort(coefs)[:top_n]\n",
    "\n",
    "        # Reverse vocabulary lookup\n",
    "        idx_to_ngram = {idx: ngram for ngram, idx in vocab.items()}\n",
    "\n",
    "        print(f\"Top {top_n} features predicting AI text:\")\n",
    "        for idx in top_ai_indices:\n",
    "            if idx in idx_to_ngram:\n",
    "                print(f\"  '{idx_to_ngram[idx]}': {coefs[idx]:.4f}\")\n",
    "\n",
    "        print(f\"\\nTop {top_n} features predicting Human text:\")\n",
    "        for idx in top_human_indices:\n",
    "            if idx in idx_to_ngram:\n",
    "                print(f\"  '{idx_to_ngram[idx]}': {coefs[idx]:.4f}\")\n",
    "\n",
    "\n",
    "analyze_features_by_ngram_length(vectorizer, models, top_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_bias_analysis(df_test: pd.DataFrame, y_pred_proba: np.ndarray, decision_threshold: float = 0.5) -> None:\n",
    "    \"\"\"Analyze dataset-specific biases and patterns.\n",
    "\n",
    "    Reveals:\n",
    "    - Per-dataset prediction distributions\n",
    "    - Dataset separability (potential artifacts)\n",
    "    - Source-specific biases\n",
    "    \"\"\"\n",
    "    _fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "    df_analysis = df_test.copy()\n",
    "    df_analysis[\"pred_proba_ai\"] = y_pred_proba[:, 1]\n",
    "    df_analysis[\"pred_label\"] = (y_pred_proba[:, 1] > decision_threshold).astype(int)\n",
    "    df_analysis[\"correct\"] = df_analysis[\"pred_label\"] == df_analysis[\"label\"]\n",
    "\n",
    "    # 1. Prediction distribution by dataset\n",
    "    ax = axes[0, 0]\n",
    "\n",
    "    datasets = df_analysis[\"dataset\"].unique()\n",
    "    datasets_sorted = sorted(datasets, key=lambda d: df_analysis[df_analysis[\"dataset\"] == d][\"pred_proba_ai\"].mean())\n",
    "\n",
    "    data_violin = [\n",
    "        df_analysis[df_analysis[\"dataset\"] == d][\"pred_proba_ai\"].to_numpy() for d in datasets_sorted[:15]\n",
    "    ]  # Top 15 for readability\n",
    "\n",
    "    parts = ax.violinplot(data_violin, positions=range(len(data_violin)), showmeans=True, showmedians=True)\n",
    "\n",
    "    for pc in parts[\"bodies\"]:\n",
    "        pc.set_facecolor(\"#9b59b6\")\n",
    "        pc.set_alpha(0.7)\n",
    "\n",
    "    ax.set_xticks(range(len(datasets_sorted[:15])))\n",
    "    ax.set_xticklabels([d[:20] for d in datasets_sorted[:15]], rotation=45, ha=\"right\")\n",
    "    ax.set_ylabel(\"Predicted Probability (AI class)\")\n",
    "    ax.set_title(\"Prediction Distribution by Dataset (Top 15)\")\n",
    "    ax.axhline(y=decision_threshold, color=\"red\", linestyle=\"--\", linewidth=1, label=\"Decision Boundary\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # 2. Dataset accuracy vs AI proportion\n",
    "    ax = axes[0, 1]\n",
    "\n",
    "    dataset_stats = (\n",
    "        df_analysis.groupby(\"dataset\").agg({\"correct\": \"mean\", \"label\": \"mean\", \"pred_proba_ai\": \"mean\"}).reset_index()\n",
    "    )\n",
    "\n",
    "    dataset_stats.columns = [\"dataset\", \"accuracy\", \"true_ai_ratio\", \"pred_ai_avg\"]\n",
    "\n",
    "    scatter = ax.scatter(\n",
    "        dataset_stats[\"true_ai_ratio\"],\n",
    "        dataset_stats[\"accuracy\"],\n",
    "        s=dataset_stats[\"pred_ai_avg\"] * 500,\n",
    "        c=dataset_stats[\"pred_ai_avg\"],\n",
    "        cmap=\"RdYlBu_r\",\n",
    "        alpha=0.6,\n",
    "        edgecolors=\"black\",\n",
    "        linewidth=1,\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"True AI Ratio in Dataset\")\n",
    "    ax.set_ylabel(\"Classification Accuracy\")\n",
    "    ax.set_title(\"Dataset Accuracy vs AI Content Ratio\\n(bubble size = avg predicted AI prob)\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Add colorbar\n",
    "    cbar = plt.colorbar(scatter, ax=ax)\n",
    "    cbar.set_label(\"Avg Predicted AI Prob\")\n",
    "\n",
    "    # Annotate outliers\n",
    "    for _, row in dataset_stats.iterrows():\n",
    "        if row[\"accuracy\"] < 0.85 or abs(row[\"true_ai_ratio\"] - row[\"pred_ai_avg\"]) > 0.3:\n",
    "            ax.annotate(\n",
    "                row[\"dataset\"][:15],\n",
    "                xy=(row[\"true_ai_ratio\"], row[\"accuracy\"]),\n",
    "                xytext=(5, 5),\n",
    "                textcoords=\"offset points\",\n",
    "                fontsize=7,\n",
    "                alpha=0.7,\n",
    "            )\n",
    "\n",
    "    # 3. Confusion heatmap by dataset\n",
    "    ax = axes[1, 0]\n",
    "\n",
    "    # Get top datasets by size\n",
    "    top_datasets = df_analysis[\"dataset\"].value_counts().head(12).index\n",
    "    df_top = df_analysis[df_analysis[\"dataset\"].isin(top_datasets)]\n",
    "\n",
    "    # Create confusion matrix per dataset\n",
    "    confusion_data = []\n",
    "    dataset_labels = []\n",
    "\n",
    "    for dataset in top_datasets:\n",
    "        df_ds = df_top[df_top[\"dataset\"] == dataset]\n",
    "        tp = ((df_ds[\"label\"] == 1) & (df_ds[\"pred_label\"] == 1)).sum()\n",
    "        fp = ((df_ds[\"label\"] == 0) & (df_ds[\"pred_label\"] == 1)).sum()\n",
    "        tn = ((df_ds[\"label\"] == 0) & (df_ds[\"pred_label\"] == 0)).sum()\n",
    "        fn = ((df_ds[\"label\"] == 1) & (df_ds[\"pred_label\"] == 0)).sum()\n",
    "\n",
    "        total = tp + fp + tn + fn\n",
    "        confusion_data.append([tn / total, fp / total, fn / total, tp / total])\n",
    "        dataset_labels.append(dataset[:20])\n",
    "\n",
    "    confusion_matrix = np.array(confusion_data)\n",
    "\n",
    "    im = ax.imshow(confusion_matrix, cmap=\"RdYlGn\", aspect=\"auto\", vmin=0, vmax=1)\n",
    "\n",
    "    ax.set_xticks([0, 1, 2, 3])\n",
    "    ax.set_xticklabels([\"TN\", \"FP\", \"FN\", \"TP\"])\n",
    "    ax.set_yticks(range(len(dataset_labels)))\n",
    "    ax.set_yticklabels(dataset_labels, fontsize=8)\n",
    "    ax.set_title(\"Normalized Confusion Matrix by Dataset\")\n",
    "\n",
    "    plt.colorbar(im, ax=ax, label=\"Proportion\")\n",
    "\n",
    "    # 4. Error rate by dataset\n",
    "    ax = axes[1, 1]\n",
    "\n",
    "    error_rates = df_analysis.groupby(\"dataset\").agg({\"correct\": lambda x: 1 - x.mean()}).reset_index()\n",
    "    error_rates.columns = [\"dataset\", \"error_rate\"]\n",
    "    error_rates = error_rates.sort_values(\"error_rate\", ascending=False).head(15)\n",
    "\n",
    "    colors_err = [\n",
    "        \"#e74c3c\" if rate > 0.1 else \"#f39c12\" if rate > 0.05 else \"#2ecc71\" for rate in error_rates[\"error_rate\"]\n",
    "    ]\n",
    "\n",
    "    y_pos = np.arange(len(error_rates))\n",
    "    ax.barh(y_pos, error_rates[\"error_rate\"], color=colors_err, alpha=0.7)\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels([d[:25] for d in error_rates[\"dataset\"]], fontsize=8)\n",
    "    ax.set_xlabel(\"Error Rate\")\n",
    "    ax.set_title(\"Top 15 Datasets by Error Rate\")\n",
    "    ax.invert_yaxis()\n",
    "    ax.axvline(x=0.05, color=\"orange\", linestyle=\"--\", linewidth=1, label=\"5% threshold\")\n",
    "    ax.axvline(x=0.1, color=\"red\", linestyle=\"--\", linewidth=1, label=\"10% threshold\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis=\"x\")\n",
    "    plt.tight_layout()\n",
    "    plot_path = PLOT_DIR / \"dataset_bias_analysis.png\"\n",
    "    plt.savefig(plot_path, bbox_inches=\"tight\")\n",
    "    mlflow.log_artifact(str(plot_path))\n",
    "\n",
    "\n",
    "dataset_bias_analysis(df_test.collect().to_pandas(), ensemble.predict_proba(X_test_tfidf), best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_visualization(\n",
    "    X_tfidf: csr_matrix, y: np.ndarray, dataset_labels: np.ndarray, sample_size: int = 10_000\n",
    ") -> None:\n",
    "    \"\"\"Comprehensive visualization combining label-based and dataset-based embeddings.\n",
    "\n",
    "    Shows 6 subplots:\n",
    "    1. t-SNE colored by true label (human/AI)\n",
    "    2. t-SNE colored by dataset source\n",
    "    3. Class density contours\n",
    "    4. Dataset centroids in t-SNE space\n",
    "    5. SVD explained variance\n",
    "    6. Class centroids with separation metric\n",
    "    \"\"\"\n",
    "    # Sample for performance\n",
    "    if len(y) > sample_size:\n",
    "        rng = np.random.default_rng(SEED)\n",
    "        indices = rng.choice(len(y), sample_size, replace=False)\n",
    "        X_sample = X_tfidf[indices]\n",
    "        y_sample = y[indices]\n",
    "        dataset_sample = dataset_labels[indices]\n",
    "    else:\n",
    "        X_sample = X_tfidf\n",
    "        y_sample = y\n",
    "        dataset_sample = dataset_labels\n",
    "\n",
    "    print(f\"Sample shape: {X_sample.shape}\")\n",
    "    print(f\"Reducing from {X_sample.shape[1]} to 50 dimensions...\")\n",
    "\n",
    "    # SVD reduction: high-dim -> 50 dimensions\n",
    "    svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "    X_svd = svd.fit_transform(X_sample)\n",
    "    print(f\"SVD complete. Shape: {X_svd.shape}\")\n",
    "\n",
    "    # t-SNE: 50 dimensions -> 2 dimensions\n",
    "    print(\"Computing t-SNE embedding (50 -> 2 dimensions)...\")\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=30, max_iter=1000)\n",
    "    X_tsne = tsne.fit_transform(X_svd)\n",
    "    print(f\"t-SNE complete. Shape: {X_tsne.shape}\")\n",
    "\n",
    "    # Create figure with 3x2 layout\n",
    "    _fig, axes = plt.subplots(3, 2, figsize=(18, 24))\n",
    "\n",
    "    human_mask = y_sample == 0\n",
    "    ai_mask = y_sample == 1\n",
    "\n",
    "    # ============================================================\n",
    "    # 1. t-SNE coloured by label (human/AI)\n",
    "    # ============================================================\n",
    "    ax = axes[0, 0]\n",
    "\n",
    "    ax.scatter(\n",
    "        X_tsne[human_mask, 0],\n",
    "        X_tsne[human_mask, 1],\n",
    "        c=\"#3498db\",\n",
    "        alpha=0.4,\n",
    "        s=20,\n",
    "        label=f\"Human (n={human_mask.sum()})\",\n",
    "        edgecolors=\"none\",\n",
    "    )\n",
    "    ax.scatter(\n",
    "        X_tsne[ai_mask, 0],\n",
    "        X_tsne[ai_mask, 1],\n",
    "        c=\"#e74c3c\",\n",
    "        alpha=0.4,\n",
    "        s=20,\n",
    "        label=f\"AI (n={ai_mask.sum()})\",\n",
    "        edgecolors=\"none\",\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel(\"t-SNE Dimension 1\", fontsize=11)\n",
    "    ax.set_ylabel(\"t-SNE Dimension 2\", fontsize=11)\n",
    "    ax.set_title(\"t-SNE Embedding (Colored by True Label)\", fontsize=13, fontweight=\"bold\")\n",
    "    ax.legend(markerscale=2)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # ============================================================\n",
    "    # 2. t-SNE colored by dataset\n",
    "    # ============================================================\n",
    "    ax = axes[0, 1]\n",
    "\n",
    "    unique_datasets = np.unique(dataset_sample)\n",
    "    n_datasets = len(unique_datasets)\n",
    "    colors_ds = plt.cm.tab20(np.linspace(0, 1, n_datasets))  # type: ignore[AttributeAccessIssue]\n",
    "\n",
    "    for i, dataset in enumerate(unique_datasets[:20]):  # Limit to 20 for visibility\n",
    "        mask = dataset_sample == dataset\n",
    "        ax.scatter(\n",
    "            X_tsne[mask, 0], X_tsne[mask, 1], c=[colors_ds[i]], alpha=0.5, s=15, label=dataset[:15], edgecolors=\"none\"\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"t-SNE Dimension 1\", fontsize=11)\n",
    "    ax.set_ylabel(\"t-SNE Dimension 2\", fontsize=11)\n",
    "    ax.set_title(\"t-SNE Embedding (Colored by Dataset)\", fontsize=13, fontweight=\"bold\")\n",
    "    ax.legend(\n",
    "        bbox_to_anchor=(1.05, 1),  # loc=\"upper left\",\n",
    "        fontsize=7,\n",
    "        ncol=2,\n",
    "    )\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # ============================================================\n",
    "    # 3. Density contours by class\n",
    "    # ============================================================\n",
    "    ax = axes[1, 0]\n",
    "\n",
    "    # Calculate KDE bounds\n",
    "    x_min, x_max = X_tsne[:, 0].min(), X_tsne[:, 0].max()\n",
    "    y_min, y_max = X_tsne[:, 1].min(), X_tsne[:, 1].max()\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "    positions = np.vstack([xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # KDE for human points\n",
    "    if human_mask.sum() > 10:\n",
    "        kde_human = gaussian_kde(X_tsne[human_mask].T)\n",
    "        z_human = kde_human(positions).reshape(xx.shape)\n",
    "        ax.contour(xx, yy, z_human, colors=\"#3498db\", alpha=0.6, linewidths=2, levels=5)\n",
    "\n",
    "    # KDE for AI points\n",
    "    if ai_mask.sum() > 10:\n",
    "        kde_ai = gaussian_kde(X_tsne[ai_mask].T)\n",
    "        z_ai = kde_ai(positions).reshape(xx.shape)\n",
    "        ax.contour(xx, yy, z_ai, colors=\"#e74c3c\", alpha=0.6, linewidths=2, levels=5)\n",
    "\n",
    "    # Scatter on top\n",
    "    ax.scatter(\n",
    "        X_tsne[human_mask, 0], X_tsne[human_mask, 1], c=\"#3498db\", alpha=0.2, s=10, label=\"Human\", edgecolors=\"none\"\n",
    "    )\n",
    "    ax.scatter(X_tsne[ai_mask, 0], X_tsne[ai_mask, 1], c=\"#e74c3c\", alpha=0.2, s=10, label=\"AI\", edgecolors=\"none\")\n",
    "\n",
    "    ax.set_xlabel(\"t-SNE Dimension 1\", fontsize=11)\n",
    "    ax.set_ylabel(\"t-SNE Dimension 2\", fontsize=11)\n",
    "    ax.set_title(\"Class Density Contours\", fontsize=13, fontweight=\"bold\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # ============================================================\n",
    "    # 4. Dataset centroids in t-SNE space\n",
    "    # ============================================================\n",
    "    ax = axes[1, 1]\n",
    "\n",
    "    # Compute centroids per dataset\n",
    "    centroids = []\n",
    "    centroid_labels = []\n",
    "    centroid_colors = []\n",
    "\n",
    "    for dataset in unique_datasets[:15]:\n",
    "        mask = dataset_sample == dataset\n",
    "        if mask.sum() > 10:  # Only if sufficient samples\n",
    "            centroid = X_tsne[mask].mean(axis=0)\n",
    "            centroids.append(centroid)\n",
    "            centroid_labels.append(dataset[:15])\n",
    "\n",
    "            # Color by majority label\n",
    "            majority_label = y_sample[mask].mean()\n",
    "            color = \"#e74c3c\" if majority_label > 0.5 else \"#3498db\"\n",
    "            centroid_colors.append(color)\n",
    "\n",
    "    centroids = np.array(centroids)\n",
    "\n",
    "    # Plot all points in background (light)\n",
    "    ax.scatter(X_tsne[:, 0], X_tsne[:, 1], c=\"gray\", alpha=0.1, s=5, edgecolors=\"none\")\n",
    "\n",
    "    # Plot centroids\n",
    "    ax.scatter(centroids[:, 0], centroids[:, 1], c=centroid_colors, s=200, alpha=0.8, edgecolors=\"black\", linewidth=2)\n",
    "\n",
    "    # Annotate centroids\n",
    "    for i, label in enumerate(centroid_labels):\n",
    "        ax.annotate(\n",
    "            label,\n",
    "            xy=(centroids[i, 0], centroids[i, 1]),\n",
    "            fontsize=7,\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            fontweight=\"bold\",\n",
    "            color=\"white\",\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"t-SNE Dimension 1\", fontsize=11)\n",
    "    ax.set_ylabel(\"t-SNE Dimension 2\", fontsize=11)\n",
    "    ax.set_title(\n",
    "        \"Dataset Centroids in t-SNE Space\\n(Blue=Human-majority, Red=AI-majority)\", fontsize=13, fontweight=\"bold\"\n",
    "    )\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # ============================================================\n",
    "    # 5. SVD explained variance\n",
    "    # ============================================================\n",
    "    ax = axes[2, 0]\n",
    "\n",
    "    cumsum_var = np.cumsum(svd.explained_variance_ratio_)\n",
    "    ax.plot(range(1, len(cumsum_var) + 1), cumsum_var, linewidth=2, color=\"#9b59b6\")\n",
    "    ax.axhline(y=0.5, color=\"red\", linestyle=\"--\", linewidth=1, label=\"50%\")\n",
    "    ax.axhline(y=0.8, color=\"orange\", linestyle=\"--\", linewidth=1, label=\"80%\")\n",
    "    ax.set_xlabel(\"Number of SVD Components\", fontsize=11)\n",
    "    ax.set_ylabel(\"Cumulative Explained Variance\", fontsize=11)\n",
    "    ax.set_title(\"SVD Variance Explained\", fontsize=13, fontweight=\"bold\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Add text showing how many components needed\n",
    "    comp_50 = np.argmax(cumsum_var >= 0.5) + 1 if any(cumsum_var >= 0.5) else 50\n",
    "    comp_80 = np.argmax(cumsum_var >= 0.8) + 1 if any(cumsum_var >= 0.8) else 50\n",
    "\n",
    "    ax.text(\n",
    "        0.05,\n",
    "        0.95,\n",
    "        f\"50% variance: {comp_50} components\\n\"\n",
    "        f\"80% variance: {comp_80} components\\n\"\n",
    "        f\"Total variance (50 comp): {cumsum_var[-1]:.3f}\",\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=10,\n",
    "        verticalalignment=\"top\",\n",
    "        bbox={\"boxstyle\": \"round\", \"facecolor\": \"wheat\", \"alpha\": 0.5},\n",
    "    )\n",
    "\n",
    "    # ============================================================\n",
    "    # 6. Class centroids with separation metric\n",
    "    # ============================================================\n",
    "    ax = axes[2, 1]\n",
    "\n",
    "    # Calculate centroids\n",
    "    centroid_human = X_tsne[human_mask].mean(axis=0)\n",
    "    centroid_ai = X_tsne[ai_mask].mean(axis=0)\n",
    "\n",
    "    # Plot all points\n",
    "    ax.scatter(\n",
    "        X_tsne[human_mask, 0], X_tsne[human_mask, 1], c=\"#3498db\", alpha=0.3, s=15, label=\"Human\", edgecolors=\"none\"\n",
    "    )\n",
    "    ax.scatter(X_tsne[ai_mask, 0], X_tsne[ai_mask, 1], c=\"#e74c3c\", alpha=0.3, s=15, label=\"AI\", edgecolors=\"none\")\n",
    "\n",
    "    # Plot centroids\n",
    "    ax.scatter(\n",
    "        *centroid_human, c=\"blue\", s=500, marker=\"*\", edgecolors=\"black\", linewidth=2, label=\"Human centroid\", zorder=5\n",
    "    )\n",
    "    ax.scatter(*centroid_ai, c=\"red\", s=500, marker=\"*\", edgecolors=\"black\", linewidth=2, label=\"AI centroid\", zorder=5)\n",
    "\n",
    "    # Draw line between centroids\n",
    "    ax.plot(\n",
    "        [centroid_human[0], centroid_ai[0]],\n",
    "        [centroid_human[1], centroid_ai[1]],\n",
    "        \"k--\",\n",
    "        linewidth=2,\n",
    "        alpha=0.5,\n",
    "        label=\"Centroid separation\",\n",
    "    )\n",
    "\n",
    "    # Calculate and display separation distance\n",
    "    separation = np.linalg.norm(centroid_ai - centroid_human)\n",
    "\n",
    "    ax.set_xlabel(\"t-SNE Dimension 1\", fontsize=11)\n",
    "    ax.set_ylabel(\"t-SNE Dimension 2\", fontsize=11)\n",
    "    ax.set_title(f\"Class Centroids (Separation: {separation:.2f})\", fontsize=13, fontweight=\"bold\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Add interpretation text\n",
    "    interpretation = \" Large separation = easy classification\\n\"\n",
    "    interpretation += \" Small separation = difficult task\\n\"\n",
    "    interpretation += \" Distinct clusters = clear patterns\\n\"\n",
    "    interpretation += \" Mixed points = overlapping features\"\n",
    "\n",
    "    ax.text(\n",
    "        0.02,\n",
    "        0.98,\n",
    "        interpretation,\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=9,\n",
    "        verticalalignment=\"top\",\n",
    "        bbox={\"boxstyle\": \"round\", \"facecolor\": \"lightyellow\", \"alpha\": 0.8},\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plot_path = PLOT_DIR / \"embedding_visualization.png\"\n",
    "    plt.savefig(plot_path, bbox_inches=\"tight\")\n",
    "    mlflow.log_artifact(str(plot_path))\n",
    "\n",
    "\n",
    "# Usage:\n",
    "embedding_visualization(\n",
    "    X_test_tfidf, y_test, df_test.select(\"dataset\").collect().to_series().to_numpy(), sample_size=20_000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_token_distributions(texts_human: pl.Series, texts_ai: pl.Series) -> None:\n",
    "    \"\"\"Compare token frequency distributions.\"\"\"\n",
    "    enc = tiktoken.get_encoding(\"o200k_base\")\n",
    "\n",
    "    tokens_human = [t for text in texts_human for t in enc.encode(text)]\n",
    "    tokens_ai = [t for text in texts_ai for t in enc.encode(text)]\n",
    "\n",
    "    freq_human = Counter(tokens_human)\n",
    "    freq_ai = Counter(tokens_ai)\n",
    "\n",
    "    # Calculate KL divergence\n",
    "    vocab = set(freq_human.keys()) | set(freq_ai.keys())\n",
    "    p = np.array([freq_human.get(t, 0) for t in vocab]) + 1e-10\n",
    "    q = np.array([freq_ai.get(t, 0) for t in vocab]) + 1e-10\n",
    "    p /= p.sum()\n",
    "    q /= q.sum()\n",
    "\n",
    "    kl_div = entropy(p, q)\n",
    "    print(f\"KL divergence (Human || AI): {kl_div:.4f}\")\n",
    "\n",
    "    # Plot token rank distributions (Zipf's law)\n",
    "    _fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    rank_human = sorted(freq_human.values(), reverse=True)\n",
    "    rank_ai = sorted(freq_ai.values(), reverse=True)\n",
    "\n",
    "    ax[0].loglog(rank_human, label=\"Human\")\n",
    "    ax[0].loglog(rank_ai, label=\"AI\", alpha=0.7)\n",
    "    ax[0].set_title(\"Token Frequency Distributions\")\n",
    "    ax[0].legend()\n",
    "\n",
    "    # Plot unique token counts\n",
    "    ax[1].bar([\"Human\", \"AI\"], [len(freq_human), len(freq_ai)])\n",
    "    ax[1].set_title(\"Vocabulary Size\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plot_path = PLOT_DIR / \"token_distribution_comparison.png\"\n",
    "    plt.savefig(plot_path, bbox_inches=\"tight\")\n",
    "    mlflow.log_artifact(str(plot_path))\n",
    "\n",
    "\n",
    "texts_human = df_test.filter(pl.col(\"label\") == 0).select(\"text\").collect().to_series()\n",
    "texts_ai = df_test.filter(pl.col(\"label\") == 1).select(\"text\").collect().to_series()\n",
    "compare_token_distributions(texts_human, texts_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def artifact_position_analysis(\n",
    "    texts: list[str],\n",
    "    labels: np.ndarray,\n",
    "    vectorizer: TfidfVectorizer,\n",
    "    model: dict[str, ClassifierMixin],\n",
    "    decision_threshold: float = 0.5,\n",
    ") -> None:\n",
    "    \"\"\"Analyze if model relies on positional artifacts (start/end of documents).\n",
    "\n",
    "    Reveals:\n",
    "    - Positional feature importance\n",
    "    - Boundary artifact detection\n",
    "    - Content vs structural learning\n",
    "    \"\"\"\n",
    "    enc = tiktoken.get_encoding(\"o200k_base\")\n",
    "\n",
    "    _fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "    # Extract positional chunks\n",
    "    start_chunks = []\n",
    "    middle_chunks = []\n",
    "    end_chunks = []\n",
    "    chunk_labels = []\n",
    "\n",
    "    print(f\"Extracting positional chunks from {len(texts)} texts...\")\n",
    "    for text, label in zip(texts, labels, strict=False):\n",
    "        tokens = enc.encode(text)\n",
    "\n",
    "        if len(tokens) < 100:\n",
    "            continue\n",
    "\n",
    "        # Take first/last/middle 50 tokens\n",
    "        chunk_size = min(50, len(tokens) // 5)\n",
    "\n",
    "        start = enc.decode(tokens[:chunk_size])\n",
    "        end = enc.decode(tokens[-chunk_size:])\n",
    "        mid_start = len(tokens) // 2 - chunk_size // 2\n",
    "        middle = enc.decode(tokens[mid_start : mid_start + chunk_size])\n",
    "\n",
    "        start_chunks.append(start)\n",
    "        middle_chunks.append(middle)\n",
    "        end_chunks.append(end)\n",
    "        chunk_labels.append(label)\n",
    "\n",
    "    chunk_labels = np.array(chunk_labels)\n",
    "\n",
    "    # Vectorize chunks\n",
    "    print(\"Vectorizing chunks...\")\n",
    "    X_start = vectorizer.transform(start_chunks)\n",
    "    X_middle = vectorizer.transform(middle_chunks)\n",
    "    X_end = vectorizer.transform(end_chunks)\n",
    "\n",
    "    # Predict on chunks\n",
    "    prob_start = model.predict_proba(X_start)[:, 1]\n",
    "    prob_middle = model.predict_proba(X_middle)[:, 1]\n",
    "    prob_end = model.predict_proba(X_end)[:, 1]\n",
    "\n",
    "    # 1. Position prediction comparison\n",
    "    ax = axes[0, 0]\n",
    "\n",
    "    positions = [\"Start\", \"Middle\", \"End\"]\n",
    "    human_mask = chunk_labels == 0\n",
    "    ai_mask = chunk_labels == 1\n",
    "\n",
    "    data_human = [prob_start[human_mask], prob_middle[human_mask], prob_end[human_mask]]\n",
    "\n",
    "    data_ai = [prob_start[ai_mask], prob_middle[ai_mask], prob_end[ai_mask]]\n",
    "\n",
    "    x = np.arange(len(positions))\n",
    "    width = 0.35\n",
    "\n",
    "    means_human = [np.mean(d) for d in data_human]\n",
    "    stds_human = [np.std(d) for d in data_human]\n",
    "    means_ai = [np.mean(d) for d in data_ai]\n",
    "    stds_ai = [np.std(d) for d in data_ai]\n",
    "\n",
    "    ax.bar(\n",
    "        x - width / 2, means_human, width, yerr=stds_human, label=\"Human (true)\", color=\"#3498db\", alpha=0.7, capsize=5\n",
    "    )\n",
    "    ax.bar(x + width / 2, means_ai, width, yerr=stds_ai, label=\"AI (true)\", color=\"#e74c3c\", alpha=0.7, capsize=5)\n",
    "\n",
    "    ax.set_ylabel(\"Mean Predicted Probability (AI class)\")\n",
    "    ax.set_title(\"Model Predictions by Document Position\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(positions)\n",
    "    ax.legend()\n",
    "    ax.axhline(y=decision_threshold, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "    ax.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "    # 2. Position correlation scatter\n",
    "    ax = axes[0, 1]\n",
    "\n",
    "    ax.scatter(prob_start[human_mask], prob_end[human_mask], alpha=0.4, s=20, color=\"#3498db\", label=\"Human\")\n",
    "    ax.scatter(prob_start[ai_mask], prob_end[ai_mask], alpha=0.4, s=20, color=\"#e74c3c\", label=\"AI\")\n",
    "\n",
    "    # Line of best fit (all points)\n",
    "    all_x = np.concatenate([prob_start[human_mask], prob_start[ai_mask]])\n",
    "    all_y = np.concatenate([prob_end[human_mask], prob_end[ai_mask]])\n",
    "    m, b = np.polyfit(all_x, all_y, 1)\n",
    "    ax.plot([0, 1], [m * 0 + b, m * 1 + b], color=\"black\", linestyle=\":\", linewidth=2, label=\"Best fit\")\n",
    "    # Perpendicular separation line through the mean\n",
    "    x_mean = np.mean(all_x)\n",
    "    y_mean = np.mean(all_y)\n",
    "    m_perp = -1 / m if m != 0 else 0  # Perpendicular slope\n",
    "    # y = m_perp * (x - x_mean) + y_mean\n",
    "    x_vals = np.array([0, 1])\n",
    "    y_perp = m_perp * (x_vals - x_mean) + y_mean\n",
    "    ax.plot(x_vals, y_perp, color=\"purple\", linestyle=\"--\", linewidth=2, label=\"Separation boundary\")\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], \"k--\", linewidth=1, alpha=0.5)\n",
    "    ax.set_xlabel(\"Prediction on START chunk\")\n",
    "    ax.set_ylabel(\"Prediction on END chunk\")\n",
    "    ax.set_title(\"Start vs End Chunk Predictions\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Calculate correlation\n",
    "    corr_start_end = np.corrcoef(prob_start, prob_end)[0, 1]\n",
    "    ax.text(\n",
    "        0.05,\n",
    "        0.95,\n",
    "        f\"Correlation: {corr_start_end:.3f}\",\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=10,\n",
    "        verticalalignment=\"top\",\n",
    "        bbox={\"boxstyle\": \"round\", \"facecolor\": \"wheat\", \"alpha\": 0.5},\n",
    "    )\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_ylim([0, 1])\n",
    "\n",
    "    # 3. Accuracy by position\n",
    "    ax = axes[1, 0]\n",
    "\n",
    "    acc_start = ((prob_start > decision_threshold) == chunk_labels).mean()\n",
    "    acc_middle = ((prob_middle > decision_threshold) == chunk_labels).mean()\n",
    "    acc_end = ((prob_end > decision_threshold) == chunk_labels).mean()\n",
    "\n",
    "    accuracies = [acc_start, acc_middle, acc_end]\n",
    "    colors_acc = [\"#e74c3c\" if a == max(accuracies) else \"#3498db\" for a in accuracies]\n",
    "\n",
    "    bars = ax.bar(positions, accuracies, color=colors_acc, alpha=0.7)\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.set_title(\"Classification Accuracy by Position\")\n",
    "    ax.set_ylim([0, 1])\n",
    "\n",
    "    # Add value labels\n",
    "    for bar, acc in zip(bars, accuracies, strict=False):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2.0, height, f\"{acc:.3f}\", ha=\"center\", va=\"bottom\", fontweight=\"bold\")\n",
    "\n",
    "    ax.grid(True, alpha=0.3, axis=\"y\")\n",
    "\n",
    "    # 4. Position variance analysis\n",
    "    ax = axes[1, 1]\n",
    "\n",
    "    # Calculate prediction variance across positions for each sample\n",
    "    all_probs = np.stack([prob_start, prob_middle, prob_end], axis=1)\n",
    "    variances = np.var(all_probs, axis=1)\n",
    "\n",
    "    # Split by correctness\n",
    "    correct_mask = (prob_middle > decision_threshold) == chunk_labels\n",
    "    var_correct = variances[correct_mask]\n",
    "    var_incorrect = variances[~correct_mask]\n",
    "\n",
    "    ax.hist(var_correct, bins=30, alpha=0.6, color=\"#2ecc71\", label=\"Correct\", density=True)\n",
    "    ax.hist(var_incorrect, bins=30, alpha=0.6, color=\"#e74c3c\", label=\"Incorrect\", density=True)\n",
    "    ax.set_xlabel(\"Prediction Variance Across Positions\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "    ax.set_title(\"Position Variance by Correctness\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # Add interpretation text\n",
    "    mean_var_correct = np.mean(var_correct)\n",
    "    mean_var_incorrect = np.mean(var_incorrect)\n",
    "\n",
    "    interpretation = \"High variance = position-dependent predictions (artifacts)\\n\"\n",
    "    interpretation += f\"Mean var (correct): {mean_var_correct:.4f}\\n\"\n",
    "    interpretation += f\"Mean var (incorrect): {mean_var_incorrect:.4f}\"\n",
    "\n",
    "    ax.text(\n",
    "        0.98,\n",
    "        0.97,\n",
    "        interpretation,\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=9,\n",
    "        verticalalignment=\"top\",\n",
    "        horizontalalignment=\"right\",\n",
    "        bbox={\"boxstyle\": \"round\", \"facecolor\": \"wheat\", \"alpha\": 0.7},\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plot_path = PLOT_DIR / \"artifact_position_analysis.png\"\n",
    "    plt.savefig(plot_path, bbox_inches=\"tight\")\n",
    "    mlflow.log_artifact(str(plot_path))\n",
    "\n",
    "\n",
    "artifact_position_analysis(\n",
    "    df_test.select(\"text\").collect().to_series().to_list(), y_test, vectorizer, ensemble, best_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "def per_dataset_accuracy_analysis(df_test: pl.LazyFrame) -> None:\n",
    "    svc_probs = models[\"svc\"].predict_proba(X_test_tfidf)[:, 1]\n",
    "    svc_pred = (svc_probs >= 0.444).astype(int)\n",
    "\n",
    "    # Add predictions to dataframe\n",
    "    df_test_full = df_test.with_columns([\n",
    "        pl.Series(\"prediction\", svc_pred),\n",
    "        pl.Series(\"prob_ai\", svc_probs),\n",
    "        pl.Series(\"correct\", (svc_pred == df_test.select(\"label\").collect().to_series().to_numpy()).astype(int)),\n",
    "    ])\n",
    "\n",
    "    # Accuracy by dataset source\n",
    "    accuracy_by_dataset = (\n",
    "        df_test_full.group_by(\"dataset\")\n",
    "        .agg([\n",
    "            pl.len().alias(\"count\"),\n",
    "            pl.col(\"correct\").mean().alias(\"accuracy\"),\n",
    "            pl.col(\"prob_ai\").mean().alias(\"avg_prob_ai\"),\n",
    "        ])\n",
    "        .sort(\"accuracy\")\n",
    "        .collect()\n",
    "    )\n",
    "\n",
    "    print(\"\\nAccuracy by Dataset Source:\")\n",
    "    print(accuracy_by_dataset)\n",
    "\n",
    "    # Find the hardest/easiest datasets\n",
    "    print(\"\\nEasiest datasets (might be artifacts):\")\n",
    "    print(accuracy_by_dataset.tail(5))\n",
    "\n",
    "    print(\"\\nHardest datasets (more realistic):\")\n",
    "    print(accuracy_by_dataset.head(5))\n",
    "\n",
    "\n",
    "per_dataset_accuracy_analysis(df_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End MLflow run\n",
    "mlflow.end_run()\n",
    "logger.info(\"MLflow run completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "is-it-slop-package",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
